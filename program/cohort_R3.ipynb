{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b7ba7b-433c-463c-8e5e-8b975a5be463",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building Machine Learning Systems That Don't Suck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7bb73f",
   "metadata": {},
   "source": [
    "This notebook creates a [SageMaker Pipeline](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html) to build an end-to-end Machine Learning system to solve the problem of classifying penguin species. With a SageMaker Pipeline, you can create, automate, and manage end-to-end Machine Learning workflows at scale.\n",
    "\n",
    "You can find more information about Amazon SageMaker in the [Amazon SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html). The [AWS Machine Learning Blog](https://aws.amazon.com/blogs/machine-learning/) is an excellent source to stay up-to-date with SageMaker.\n",
    "\n",
    "This example uses the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data).\n",
    "\n",
    "<img src='images/penguins.png' alt='Penguins' width=\"800\">\n",
    "\n",
    "This notebook is part of the [Machine Learning School](https://www.ml.school) program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec22ac1",
   "metadata": {},
   "source": [
    "## Session 1 - Introduction and Initial Setup\n",
    "\n",
    "The machine learning system we'll build during this program consists of four main pipelines: A **training** pipeline, an **inference** pipeline, a **deployment** pipeline, and a **monitoring** pipeline.\n",
    "\n",
    "Here is an architectural diagram showing how the system is structured:\n",
    "\n",
    "<a href=\"images/diagram.png\" target=\"_blank\"> <img src=\"images/diagram.png\" alt=\"SageMaker architectural diagram of the system\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Throughout the sessions, we'll build each of these pipelines. We'll also build variations to show you different alternatives and best practices.\n",
    "\n",
    "Let's start by setting up the environment and preparing to run the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2265b0",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import ipytest\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(exist_ok=True)\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\"])\n",
    "\n",
    "DATA_FILEPATH = \"penguins.csv\"\n",
    "\n",
    "ipytest.autoconfig(raise_on_error=True)\n",
    "\n",
    "# By default, The SageMaker SDK logs events related to the default\n",
    "# configuration using the INFO level. To prevent these from spoiling\n",
    "# the output of this notebook cells, we can change the logging\n",
    "# level to ERROR instead.\n",
    "logging.getLogger(\"sagemaker.config\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d34c9",
   "metadata": {},
   "source": [
    "We can run this notebook in [Local Mode](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-local-mode.html) to test some of the system components in your local environment. Unfortunately, not every component is supported in Local Mode.\n",
    "\n",
    "Setting the `LOCAL_MODE` variable to `True` will run every supported pipeline component locally. Setting the variable to `False` will run the pipeline in SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69daf2b8",
   "metadata": {},
   "source": [
    "## <font color = \"red\">Toggle LOCAL_MODE to run the notebook locally or on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4d764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOCAL_MODE = True\n",
    "LOCAL_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be4f8d",
   "metadata": {},
   "source": [
    "Let's now load the environment variables we need to run the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = os.environ[\"BUCKET\"]\n",
    "role = os.environ[\"ROLE\"]\n",
    "\n",
    "COMET_API_KEY = os.environ.get(\"COMET_API_KEY\", None)\n",
    "COMET_PROJECT_NAME = os.environ.get(\"COMET_PROJECT_NAME\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa700f4",
   "metadata": {},
   "source": [
    "If you are running the pipeline in Local Mode on an ARM64 machine (for example, on Apple Silicon), you will need to use a custom Docker image to train and evaluate the model. Let's create a variable indicating if we are running on an ARM64 machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc40d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can retrieve the architecture of the local\n",
    "# computer using the `uname -m` command.\n",
    "architecture = !(uname -m)\n",
    "\n",
    "IS_ARM64_ARCHITECTURE = architecture[0] == \"arm64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d906ada",
   "metadata": {},
   "source": [
    "Let's create a configuration dictionary with different settings depending on whether we are running the pipeline in Local Mode. We'll use this dictionary to configure the pipeline components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession, PipelineSession\n",
    "\n",
    "pipeline_session = PipelineSession(default_bucket=bucket) if not LOCAL_MODE else None\n",
    "\n",
    "if LOCAL_MODE:\n",
    "    config = {\n",
    "        \"session\": LocalPipelineSession(default_bucket=bucket),\n",
    "        \"instance_type\": \"local\",\n",
    "        # We need to use a custom Docker image when we run the pipeline\n",
    "        # in Local Model on an ARM64 machine.\n",
    "        \"image\": (\n",
    "            \"sagemaker-tensorflow-toolkit-local\" if IS_ARM64_ARCHITECTURE else None\n",
    "        ),\n",
    "    }\n",
    "else:\n",
    "    config = {\n",
    "        \"session\": pipeline_session,\n",
    "        \"instance_type\": \"ml.m5.xlarge\",\n",
    "        \"image\": None,\n",
    "    }\n",
    "\n",
    "# These specific settings refer to the SageMaker\n",
    "# TensorFlow container we'll use.\n",
    "config[\"framework_version\"] = \"2.12\"\n",
    "config[\"py_version\"] = \"py310\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089696b",
   "metadata": {},
   "source": [
    "Let's now initialize a few variables that we'll need throughout the notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "S3_LOCATION = f\"s3://{bucket}/penguins\"\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a835695-557b-46d8-a901-a29bc57df5fe",
   "metadata": {},
   "source": [
    "## Session 2 - Exploratory Data Analysis\n",
    "\n",
    "Let's run Exploratory Data Analysis on the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data). The goal of this session is to understand the data and the problem we are trying to solve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6943b",
   "metadata": {},
   "source": [
    "Let's load the Penguins dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd2f0e-446d-48a9-a008-b4f1cc593bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "penguins = pd.read_csv(DATA_FILEPATH)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eae10e-20c4-477e-b6b8-965c3a53566e",
   "metadata": {},
   "source": [
    "We can see the dataset contains the following columns:\n",
    "\n",
    "1. `species`: The species of a penguin. This is the column we want to predict.\n",
    "2. `island`: The island where the penguin was found\n",
    "3. `culmen_length_mm`: The length of the penguin's culmen (bill) in millimeters\n",
    "4. `culmen_depth_mm`: The depth of the penguin's culmen in millimeters\n",
    "5. `flipper_length_mm`: The length of the penguin's flipper in millimeters\n",
    "6. `body_mass_g`: The body mass of the penguin in grams\n",
    "7. `sex`: The sex of the penguin\n",
    "\n",
    "If you are curious, here is the description of a penguin's culmen:\n",
    "\n",
    "<img src='images/culmen.jpeg' alt='Culmen' width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bc0c3",
   "metadata": {},
   "source": [
    "Now, let's get the summary statistics for the features in our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2107c25-e730-4e22-a1b8-5bda53e61124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguins.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e19af7-9f0f-45fe-b7d3-f19721c02a2b",
   "metadata": {},
   "source": [
    "Let's now display the distribution of values for the three categorical columns in our data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242122a-726e-4c37-a718-dd8e873d1612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_distribution = penguins[\"species\"].value_counts()\n",
    "island_distribution = penguins[\"island\"].value_counts()\n",
    "sex_distribution = penguins[\"sex\"].value_counts()\n",
    "\n",
    "print(species_distribution, end=\"\\n\\n\")\n",
    "print(island_distribution, end=\"\\n\\n\")\n",
    "print(sex_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d98fdd-3b8c-40a2-b8dc-15162b4049e2",
   "metadata": {},
   "source": [
    "The distribution of the categories in our data are:\n",
    "\n",
    "-   `species`: There are 3 species of penguins in the dataset: Adelie (`152`), Gentoo (`124`), and Chinstrap (`68`).\n",
    "-   `island`: Penguins are from 3 islands: Biscoe (`168`), Dream (`124`), and Torgersen (`52`).\n",
    "-   `sex`: We have `168` male penguins, `165` female penguins, and `1` penguin with an ambiguous gender (`.`).\n",
    "\n",
    "Let's replace the ambiguous value in the `sex` column with a `null` value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cf582-8831-4f83-bb17-2175afb193e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguins[\"sex\"] = penguins[\"sex\"].replace(\".\", np.nan)\n",
    "\n",
    "# Let's display the new distribution of the column:\n",
    "sex_distribution = penguins[\"sex\"].value_counts()\n",
    "sex_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8425ce-ce4e-43e6-9ed8-0398b780cc66",
   "metadata": {},
   "source": [
    "Next, let's check for any missing values in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42cb08-275c-4b05-9d2b-77052da2f336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguins.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65207c-3e66-453a-87a1-751636c979ee",
   "metadata": {},
   "source": [
    "Let's get rid of the missing values. For now, we are going to replace the missing values with the most frequent value in the column. Later, we'll use a different strategy to replace missing numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57d55d-afd6-467a-a7a8-ff04132770ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "penguins.iloc[:, :] = imputer.fit_transform(penguins)\n",
    "\n",
    "# Let's display again the number of missing values:\n",
    "penguins.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758214f-a4ab-4980-8892-91ec8d218ef3",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(6, 10))\n",
    "\n",
    "axs[0].bar(species_distribution.index, species_distribution.values)\n",
    "axs[0].set_ylabel(\"Count\")\n",
    "axs[0].set_title(\"Distribution of Species\")\n",
    "\n",
    "axs[1].bar(island_distribution.index, island_distribution.values)\n",
    "axs[1].set_ylabel(\"Count\")\n",
    "axs[1].set_title(\"Distribution of Island\")\n",
    "\n",
    "axs[2].bar(sex_distribution.index, sex_distribution.values)\n",
    "axs[2].set_ylabel(\"Count\")\n",
    "axs[2].set_title(\"Distribution of Sex\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c8fae-35b4-4d8e-8fff-decee050af3a",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of numerical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707cc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "axs[0, 0].hist(penguins[\"culmen_length_mm\"], bins=20)\n",
    "axs[0, 0].set_ylabel(\"Count\")\n",
    "axs[0, 0].set_title(\"Distribution of culmen_length_mm\")\n",
    "\n",
    "axs[0, 1].hist(penguins[\"culmen_depth_mm\"], bins=20)\n",
    "axs[0, 1].set_ylabel(\"Count\")\n",
    "axs[0, 1].set_title(\"Distribution of culmen_depth_mm\")\n",
    "\n",
    "axs[1, 0].hist(penguins[\"flipper_length_mm\"], bins=20)\n",
    "axs[1, 0].set_ylabel(\"Count\")\n",
    "axs[1, 0].set_title(\"Distribution of flipper_length_mm\")\n",
    "\n",
    "axs[1, 1].hist(penguins[\"body_mass_g\"], bins=20)\n",
    "axs[1, 1].set_ylabel(\"Count\")\n",
    "axs[1, 1].set_title(\"Distribution of body_mass_g\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef241df0-3acd-4401-a2c6-b70723d7595b",
   "metadata": {},
   "source": [
    "Let's display the covariance matrix of the dataset. The \"covariance\" measures how changes in one variable are associated with changes in a second variable. In other words, the covariance measures the degree to which two variables are linearly associated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf3ba1-d218-4ad4-b862-af679b91273f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguins.cov(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbe6bc-0104-4663-8c30-8f9566755739",
   "metadata": {},
   "source": [
    "Here are three examples of what we get from interpreting the covariance matrix below:\n",
    "\n",
    "1. The positive covariance of 50.26 between culmen length and flippler length suggests that larger values of culmen length are associated with larger values of flipper length. As one increases, generally so does the other.\n",
    "2. The positive covariance of 2596.97 between culmen length and body mass suggests that heavier penguins generally have longer culmens. There is a tendency for these two variables to increase together.\n",
    "3. The negative covariance of -742.66 between culmen depth and body mass suggests a general tendency that penguins with deeper culmens weigh less.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81117f",
   "metadata": {},
   "source": [
    "Let's now display the correlation matrix. \"Correlation\" measures both the strength and direction of the linear relationship between two variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d793e09-2cb9-47ff-a0e6-199a0f4fc1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "penguins.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec4c08-767c-4740-959c-2d76268c3513",
   "metadata": {},
   "source": [
    "Here are three examples of what we get from interpreting the correlation matrix below:\n",
    "\n",
    "1. Penguins that weight more tend to have longer flippers.\n",
    "2. Penguins with a shallower culmen tend to have longer flippers.\n",
    "3. Penguins with longer culmens tend to have longer flippers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fef0cf",
   "metadata": {},
   "source": [
    "Let's display the distribution of species by island:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = penguins[\"species\"].unique()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for species in unique_species:\n",
    "    data = penguins[penguins[\"species\"] == species]\n",
    "    ax.hist(data[\"island\"], bins=5, alpha=0.5, label=species)\n",
    "\n",
    "ax.set_xlabel(\"Island\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Species by Island\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ae740-3590-4dce-ac5a-6205975c83da",
   "metadata": {},
   "source": [
    "Let's display the distribution of species by sex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0a87f-028d-477f-9b65-199728c0b7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "for species in unique_species:\n",
    "    data = penguins[penguins[\"species\"] == species]\n",
    "    ax.hist(data[\"sex\"], bins=3, alpha=0.5, label=species)\n",
    "\n",
    "ax.set_xlabel(\"Sex\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Species by Sex\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11137928-6b4e-465c-8ad7-2297afbaa33c",
   "metadata": {},
   "source": [
    "## Session 3 - Splitting and Transforming the Data\n",
    "\n",
    "In this session we'll build a simple [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with one step to split and transform the data:\n",
    "\n",
    "<a href=\"images/processing-step.png\" target=\"_blank\"> <img src=\"images/processing-step.png\" alt=\"High-level overview of the Preprocessing Step\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We'll use a [Scikit-Learn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for the transformations, and a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) with a [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) to execute a preprocessing script. Check the [SageMaker Pipelines Overview](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) for an introduction to the fundamental components of a SageMaker Pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d06e0-b711-4e3d-b424-6fa611a51f94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1 - Creating the Preprocessing Script\n",
    "\n",
    "The first step we need in the pipeline is a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) to run a script that will split and transform the data.\n",
    "\n",
    "This Processing Step will create a SageMaker Processing Job in the background, run the script, and upload the output to S3. You can use Processing Jobs to perform data preprocessing, post-processing, feature engineering, data validation, and model evaluation. Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6f546",
   "metadata": {},
   "source": [
    "We will store the script in a folder called `processing` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"processing\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b8e0c",
   "metadata": {},
   "source": [
    "Let's now create the script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ba7c0-1bd6-4fe5-8b7f-f6cbdfd3846c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/processing/script.py\n",
    "# | filename: script.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def preprocess(base_directory):\n",
    "    \"\"\"Load the supplied data, split it and transform it.\"\"\"\n",
    "    df = _read_data_from_input_csv_files(base_directory)\n",
    "\n",
    "    target_transformer = ColumnTransformer(\n",
    "        transformers=[(\"species\", OrdinalEncoder(), [0])],\n",
    "    )\n",
    "\n",
    "    numeric_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"mean\"),\n",
    "        StandardScaler(),\n",
    "    )\n",
    "\n",
    "    categorical_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        OneHotEncoder(),\n",
    "    )\n",
    "\n",
    "    features_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"numeric\",\n",
    "                numeric_transformer,\n",
    "                make_column_selector(dtype_exclude=\"object\"),\n",
    "            ),\n",
    "            (\"categorical\", categorical_transformer, [\"island\"]),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df_train, df_validation, df_test = _split_data(df)\n",
    "\n",
    "    _save_train_baseline(base_directory, df_train)\n",
    "    _save_test_baseline(base_directory, df_test)\n",
    "\n",
    "    y_train = target_transformer.fit_transform(\n",
    "        np.array(df_train.species.values).reshape(-1, 1),\n",
    "    )\n",
    "    y_validation = target_transformer.transform(\n",
    "        np.array(df_validation.species.values).reshape(-1, 1),\n",
    "    )\n",
    "    y_test = target_transformer.transform(\n",
    "        np.array(df_test.species.values).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "    df_train = df_train.drop(\"species\", axis=1)\n",
    "    df_validation = df_validation.drop(\"species\", axis=1)\n",
    "    df_test = df_test.drop(\"species\", axis=1)\n",
    "\n",
    "    X_train = features_transformer.fit_transform(df_train)  # noqa: N806\n",
    "    X_validation = features_transformer.transform(df_validation)  # noqa: N806\n",
    "    X_test = features_transformer.transform(df_test)  # noqa: N806\n",
    "\n",
    "    _save_splits(\n",
    "        base_directory,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_validation,\n",
    "        y_validation,\n",
    "        X_test,\n",
    "        y_test,\n",
    "    )\n",
    "    _save_model(base_directory, target_transformer, features_transformer)\n",
    "\n",
    "\n",
    "def _read_data_from_input_csv_files(base_directory):\n",
    "    \"\"\"Read the data from the input CSV files.\n",
    "\n",
    "    This function reads every CSV file available and\n",
    "    concatenates them into a single dataframe.\n",
    "    \"\"\"\n",
    "    input_directory = Path(base_directory) / \"input\"\n",
    "    files = list(input_directory.glob(\"*.csv\"))\n",
    "\n",
    "    if len(files) == 0:\n",
    "        message = f\"The are no CSV files in {input_directory.as_posix()}/\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "    raw_data = [pd.read_csv(file) for file in files]\n",
    "    df = pd.concat(raw_data)\n",
    "\n",
    "    # Shuffle the data\n",
    "    return df.sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "def _split_data(df):\n",
    "    \"\"\"Split the data into train, validation, and test.\"\"\"\n",
    "    df_train, temp = train_test_split(df, test_size=0.3)\n",
    "    df_validation, df_test = train_test_split(temp, test_size=0.5)\n",
    "\n",
    "    return df_train, df_validation, df_test\n",
    "\n",
    "\n",
    "def _save_train_baseline(base_directory, df_train):\n",
    "    \"\"\"Save the untransformed training data to disk.\n",
    "\n",
    "    We will need the training data to compute a baseline to\n",
    "    determine the quality of the data that the model receives\n",
    "    when deployed.\n",
    "    \"\"\"\n",
    "    baseline_path = Path(base_directory) / \"train-baseline\"\n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = df_train.copy().dropna()\n",
    "\n",
    "    # To compute the data quality baseline, we don't need the\n",
    "    # target variable, so we'll drop it from the dataframe.\n",
    "    df = df.drop(\"species\", axis=1)\n",
    "\n",
    "    df.to_csv(baseline_path / \"train-baseline.csv\", header=True, index=False)\n",
    "\n",
    "\n",
    "def _save_test_baseline(base_directory, df_test):\n",
    "    \"\"\"Save the untransformed test data to disk.\n",
    "\n",
    "    We will need the test data to compute a baseline to\n",
    "    determine the quality of the model predictions when deployed.\n",
    "    \"\"\"\n",
    "    baseline_path = Path(base_directory) / \"test-baseline\"\n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = df_test.copy().dropna()\n",
    "\n",
    "    # We'll use the test baseline to generate predictions later,\n",
    "    # and we can't have a header line because the model won't be\n",
    "    # able to make a prediction for it.\n",
    "    df.to_csv(baseline_path / \"test-baseline.csv\", header=False, index=False)\n",
    "\n",
    "\n",
    "def _save_splits(\n",
    "    base_directory,\n",
    "    X_train,  # noqa: N803\n",
    "    y_train,\n",
    "    X_validation,  # noqa: N803\n",
    "    y_validation,\n",
    "    X_test,  # noqa: N803\n",
    "    y_test,\n",
    "):\n",
    "    \"\"\"Save data splits to disk.\n",
    "\n",
    "    This function concatenates the transformed features\n",
    "    and the target variable, and saves each one of the split\n",
    "    sets to disk.\n",
    "    \"\"\"\n",
    "    train = np.concatenate((X_train, y_train), axis=1)\n",
    "    validation = np.concatenate((X_validation, y_validation), axis=1)\n",
    "    test = np.concatenate((X_test, y_test), axis=1)\n",
    "\n",
    "    train_path = Path(base_directory) / \"train\"\n",
    "    validation_path = Path(base_directory) / \"validation\"\n",
    "    test_path = Path(base_directory) / \"test\"\n",
    "\n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        validation_path / \"validation.csv\",\n",
    "        header=False,\n",
    "        index=False,\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "\n",
    "\n",
    "def _save_model(base_directory, target_transformer, features_transformer):\n",
    "    \"\"\"Save the Scikit-Learn transformation pipelines.\n",
    "\n",
    "    This function creates a model.tar.gz file that\n",
    "    contains the two transformation pipelines we built\n",
    "    to transform the data.\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as directory:\n",
    "        joblib.dump(target_transformer, Path(directory) / \"target.joblib\")\n",
    "        joblib.dump(features_transformer, Path(directory) / \"features.joblib\")\n",
    "\n",
    "        model_path = Path(base_directory) / \"model\"\n",
    "        model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with tarfile.open(f\"{(model_path / 'model.tar.gz').as_posix()}\", \"w:gz\") as tar:\n",
    "            tar.add(Path(directory) / \"target.joblib\", arcname=\"target.joblib\")\n",
    "            tar.add(\n",
    "                Path(directory) / \"features.joblib\", arcname=\"features.joblib\",\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(base_directory=\"/opt/ml/processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39301f9f",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f122a4-acff-4687-91b9-bfef13567d88",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%ipytest -s\n",
    "# | code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "import pytest\n",
    "from processing.script import preprocess\n",
    "\n",
    "\n",
    "@pytest.fixture(autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "\n",
    "    directory = Path(directory)\n",
    "    preprocess(base_directory=directory)\n",
    "\n",
    "    yield directory\n",
    "\n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_preprocess_generates_data_splits(directory):\n",
    "    output_directories = os.listdir(directory)\n",
    "\n",
    "    assert \"train\" in output_directories\n",
    "    assert \"validation\" in output_directories\n",
    "    assert \"test\" in output_directories\n",
    "\n",
    "\n",
    "def test_preprocess_generates_baselines(directory):\n",
    "    output_directories = os.listdir(directory)\n",
    "\n",
    "    assert \"train-baseline\" in output_directories\n",
    "    assert \"test-baseline\" in output_directories\n",
    "\n",
    "\n",
    "def test_preprocess_creates_two_models(directory):\n",
    "    model_path = directory / \"model\"\n",
    "    tar = tarfile.open(model_path / \"model.tar.gz\", \"r:gz\")\n",
    "\n",
    "    assert \"features.joblib\" in tar.getnames()\n",
    "    assert \"target.joblib\" in tar.getnames()\n",
    "\n",
    "\n",
    "def test_splits_are_transformed(directory):\n",
    "    train = pd.read_csv(directory / \"train\" / \"train.csv\", header=None)\n",
    "    validation = pd.read_csv(directory / \"validation\" / \"validation.csv\", header=None)\n",
    "    test = pd.read_csv(directory / \"test\" / \"test.csv\", header=None)\n",
    "\n",
    "    # After transforming the data, the number of features should be 7:\n",
    "    # * 3 - island (one-hot encoded)\n",
    "    # * 1 - culmen_length_mm = 1\n",
    "    # * 1 - culmen_depth_mm\n",
    "    # * 1 - flipper_length_mm\n",
    "    # * 1 - body_mass_g\n",
    "    number_of_features = 7\n",
    "\n",
    "    # The transformed splits should have an additional column for the target\n",
    "    # variable.\n",
    "    assert train.shape[1] == number_of_features + 1\n",
    "    assert validation.shape[1] == number_of_features + 1\n",
    "    assert test.shape[1] == number_of_features + 1\n",
    "\n",
    "\n",
    "def test_train_baseline_is_not_transformed(directory):\n",
    "    baseline = pd.read_csv(\n",
    "        directory / \"train-baseline\" / \"train-baseline.csv\",\n",
    "        header=None,\n",
    "    )\n",
    "\n",
    "    island = baseline.iloc[:, 0].unique()\n",
    "\n",
    "    assert \"Biscoe\" in island\n",
    "    assert \"Torgersen\" in island\n",
    "    assert \"Dream\" in island\n",
    "\n",
    "\n",
    "def test_test_baseline_is_not_transformed(directory):\n",
    "    baseline = pd.read_csv(\n",
    "        directory / \"test-baseline\" / \"test-baseline.csv\", header=None\n",
    "    )\n",
    "\n",
    "    island = baseline.iloc[:, 1].unique()\n",
    "\n",
    "    assert \"Biscoe\" in island\n",
    "    assert \"Torgersen\" in island\n",
    "    assert \"Dream\" in island\n",
    "\n",
    "\n",
    "def test_train_baseline_includes_header(directory):\n",
    "    baseline = pd.read_csv(directory / \"train-baseline\" / \"train-baseline.csv\")\n",
    "    assert baseline.columns[0] == \"island\"\n",
    "\n",
    "\n",
    "def test_test_baseline_does_not_include_header(directory):\n",
    "    baseline = pd.read_csv(directory / \"test-baseline\" / \"test-baseline.csv\")\n",
    "    assert baseline.columns[0] != \"island\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b7a57",
   "metadata": {},
   "source": [
    "### Step 2 - Caching Configuration\n",
    "\n",
    "Several SageMaker Pipeline steps support caching. When a step runs, and dependending on the configured caching policy, SageMaker will try to reuse the result of a previous successful run of the same step. You can find more information about this topic in [Caching Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html).\n",
    "\n",
    "Let's define a caching policy that we'll reuse on every step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"15d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b3dfc",
   "metadata": {},
   "source": [
    "### Step 3 - Pipeline Configuration\n",
    "\n",
    "We can parameterize a SageMaker Pipeline to make it more flexible. In this case, we'll use a parameter to pass the location of the dataset we want to process. We can execute the pipeline with different datasets by changing the value of this parameter. Check [Pipeline Parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fe373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff9c36",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Processing Step\n",
    "\n",
    "Let's now define the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) that we'll use in the pipeline to run the script that will split and transform the data.\n",
    "\n",
    "A processor gives the Processing Step information about the hardware and software that SageMaker should use to launch a Processing Job. To run the script we created, we need access to Scikit-Learn, so we can use the [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) processor that comes out-of-the-box with the SageMaker's Python SDK.\n",
    "\n",
    "SageMaker manages the infrastructure of a Processing Job. It provisions resources for the duration of the job, and cleans up when it completes. The Processing Container image that SageMaker uses to run a Processing Job can either be a SageMaker built-in image or a custom image:\n",
    "\n",
    "<a href=\"images/processing-job.png\" target=\"_blank\"> <img src=\"images/processing-job.png\" alt=\"High-level overview of a SageMaker Processing Job\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "The [Data Processing with Framework Processors](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks.html) page discusses other built-in processors you can use. The [Docker Registry Paths and Example Code](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) page contains information about the available framework versions for each region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4471a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    # By default, a new account doesn't have access to `ml.m5.xlarge` instances.\n",
    "    # If you haven't requested a quota increase yet, you can use an\n",
    "    # `ml.t3.medium` instance type instead. This will work out of the box, but\n",
    "    # the Processing Job will take significantly longer than it should have.\n",
    "    # To get access to `ml.m5.xlarge` instances, you can request a quota\n",
    "    # increase under the Service Quotas section in your AWS account.\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2cc58",
   "metadata": {},
   "source": [
    "Let's now define the Processing Step that we'll use in the pipeline.\n",
    "\n",
    "This step will specify the list of inputs that we'll access from the preprocessing script. In this case, the input is the dataset we stored in S3. We also have a few outputs that we want SageMaker to capture when the Processing Job finishes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd9303",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    step_args=processor.run(\n",
    "        code=f\"{(CODE_FOLDER / 'processing' / 'script.py').as_posix()}\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=dataset_location,\n",
    "                destination=\"/opt/ml/processing/input\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train\",\n",
    "                source=\"/opt/ml/processing/train\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"validation\",\n",
    "                source=\"/opt/ml/processing/validation\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/validation\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test\",\n",
    "                source=\"/opt/ml/processing/test\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"model\",\n",
    "                source=\"/opt/ml/processing/model\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/model\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train-baseline\",\n",
    "                source=\"/opt/ml/processing/train-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train-baseline\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test-baseline\",\n",
    "                source=\"/opt/ml/processing/test-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test-baseline\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad062cb",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "We can now create the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140642a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "session3_pipeline = Pipeline(\n",
    "    name=\"session3-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session3_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ba122",
   "metadata": {},
   "source": [
    "#### <font color = \"red\">If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "session3_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c190c5-52b5-4ccc-8d42-847a694b8e66",
   "metadata": {},
   "source": [
    "## Session 4 - Training the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [step to train a model](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training). Check [Train a Model with TensorFlow](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow) for more information about training a model with TensorFlow.\n",
    "\n",
    "<a href=\"images/training-step.png\" target=\"_blank\"> <img src=\"images/training-step.png\" alt=\"High-level overview of the Training Step\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We'll also introduce experiment tracking using [Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) and [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8608092-7aab-4fd2-aa99-47c2db27bdb7",
   "metadata": {},
   "source": [
    "### Step 1 - Creating the Training Script\n",
    "\n",
    "Let's create the training script. This script is responsible for training a neural network using the train data, validating the model, and saving it so we can later use it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e9294",
   "metadata": {},
   "source": [
    "We will store the script in a folder called `training` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"training\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3cec9",
   "metadata": {},
   "source": [
    "We can now create the script inside the folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b121d-dcb9-43e8-9ee3-3ececb583e7e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/training/script.py\n",
    "# | filename: script.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "from pathlib import Path\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from packaging import version\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train(\n",
    "    model_directory,\n",
    "    train_path,\n",
    "    validation_path,\n",
    "    pipeline_path,\n",
    "    experiment,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "):\n",
    "    print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "    X_train = pd.read_csv(Path(train_path) / \"train.csv\")\n",
    "    y_train = X_train[X_train.columns[-1]]\n",
    "    X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "\n",
    "    X_validation = pd.read_csv(Path(validation_path) / \"validation.csv\")\n",
    "    y_validation = X_validation[X_validation.columns[-1]]\n",
    "    X_validation = X_validation.drop(X_validation.columns[-1], axis=1)\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input(shape=(X_train.shape[1],)),\n",
    "            Dense(10, activation=\"relu\"),\n",
    "            Dense(8, activation=\"relu\"),\n",
    "            Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=SGD(learning_rate=0.01),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_validation, y_validation),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    predictions = np.argmax(model.predict(X_validation), axis=-1)\n",
    "    val_accuracy = accuracy_score(y_validation, predictions)\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Starting on version 3, Keras changed the model saving format.\n",
    "    # Since we are running the training script using two different versions\n",
    "    # of Keras, we need to check to see which version we are using and save\n",
    "    # the model accordingly.\n",
    "    model_filepath = (\n",
    "        Path(model_directory) / \"001\"\n",
    "        if version.parse(keras.__version__) < version.parse(\"3\")\n",
    "        else Path(model_directory) / \"penguins.keras\"\n",
    "    )\n",
    "\n",
    "    model.save(model_filepath)\n",
    "\n",
    "    # Let's save the transformation pipelines inside the\n",
    "    # model directory so they get bundled together.\n",
    "    with tarfile.open(Path(pipeline_path) / \"model.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(model_directory)\n",
    "\n",
    "    if experiment:\n",
    "        experiment.log_parameters(\n",
    "            {\n",
    "                \"epochs\": epochs,\n",
    "                \"batch_size\": batch_size,\n",
    "            }\n",
    "        )\n",
    "        experiment.log_dataset_hash(X_train)\n",
    "        experiment.log_confusion_matrix(\n",
    "            y_validation.astype(int), predictions.astype(int)\n",
    "        )\n",
    "        experiment.log_model(\"penguins\", model_filepath.as_posix())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Any hyperparameters provided by the training job are passed to\n",
    "    # the entry point as script arguments.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Let's create a Comet experiment to log the metrics and parameters\n",
    "    # of this training job.\n",
    "    comet_api_key = os.environ.get(\"COMET_API_KEY\", None)\n",
    "    comet_project_name = os.environ.get(\"COMET_PROJECT_NAME\", None)\n",
    "\n",
    "    experiment = (\n",
    "        Experiment(\n",
    "            project_name=comet_project_name,\n",
    "            api_key=comet_api_key,\n",
    "            auto_metric_logging=True,\n",
    "            auto_param_logging=True,\n",
    "            log_code=True,\n",
    "        )\n",
    "        if comet_api_key and comet_project_name\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    training_env = json.loads(os.environ.get(\"SM_TRAINING_ENV\", {}))\n",
    "    job_name = training_env.get(\"job_name\", None) if training_env else None\n",
    "\n",
    "    # We want to use the SageMaker's training job name as the name\n",
    "    # of the experiment so we can easily recognize it.\n",
    "    if job_name and experiment:\n",
    "        experiment.set_name(job_name)\n",
    "\n",
    "    train(\n",
    "        # This is the location where we need to save our model.\n",
    "        # SageMaker will create a model.tar.gz file with anything\n",
    "        # inside this directory when the training script finishes.\n",
    "        model_directory=os.environ[\"SM_MODEL_DIR\"],\n",
    "        # SageMaker creates one channel for each one of the inputs\n",
    "        # to the Training Step.\n",
    "        train_path=os.environ[\"SM_CHANNEL_TRAIN\"],\n",
    "        validation_path=os.environ[\"SM_CHANNEL_VALIDATION\"],\n",
    "        pipeline_path=os.environ[\"SM_CHANNEL_PIPELINE\"],\n",
    "        experiment=experiment,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0a4fa-ce70-4882-b9f5-8253df03d890",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea27ce-c453-4cb0-b309-dbecd732957e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pytest\n",
    "import tempfile\n",
    "\n",
    "from processing.script import preprocess\n",
    "from training.script import train\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    \n",
    "    preprocess(base_directory=directory)\n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\", \n",
    "        validation_path=directory / \"validation\",\n",
    "        pipeline_path=directory / \"model\",\n",
    "        experiment=None,\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    yield directory\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_train_bundles_model_assets(directory):\n",
    "    bundle = os.listdir(directory / \"model\")\n",
    "    assert \"001\" in bundle\n",
    "    \n",
    "    assets = os.listdir(directory / \"model\" / \"001\")\n",
    "    assert \"saved_model.pb\" in assets\n",
    "\n",
    "\n",
    "def test_train_bundles_transformation_pipelines(directory):\n",
    "    bundle = os.listdir(directory / \"model\")\n",
    "    assert \"target.joblib\" in bundle\n",
    "    assert \"features.joblib\" in bundle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cff4c1-6510-4d99-8ae1-cb14927b87c7",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up the Training Step\n",
    "\n",
    "We can now create a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) that we can add to the pipeline. This Training Step will create a SageMaker Training Job in the background, run the training script, and upload the output to S3. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "SageMaker manages the infrastructure of a Training Job. It provisions resources for the duration of the job, and cleans up when it completes. The Training Container image that SageMaker uses to run a Training Job can either be a SageMaker built-in image or a custom image.\n",
    "\n",
    "<a href=\"images/training-job.png\" target=\"_blank\"> <img src=\"images/training-job.png\" alt=\"High-level overview of a SageMaker Training Job\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "The [Available Deep Learning Container Images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md) page contains the list of available containers for each region.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d8729",
   "metadata": {},
   "source": [
    "Our training script uses [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github) to track metrics from the Training Job. We need to create a `requirements.txt` file to install the Comet library in the training container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00eda86",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/training/requirements.txt\n",
    "#| label: requirements.txt\n",
    "#| filename: requirements.txt\n",
    "#| code-line-numbers: false\n",
    "\n",
    "comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6857eeb",
   "metadata": {},
   "source": [
    "SageMaker uses the concept of an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) to handle end-to-end training and deployment tasks. For this example, we will use the built-in [TensorFlow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to run the training script we wrote before.\n",
    "\n",
    "Notice the list of hyperparameters defined below. SageMaker will pass these hyperparameters as arguments to the entry point of the training script.\n",
    "\n",
    "We are going to use [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github) and [SageMaker Experiments](https://sagemaker.readthedocs.io/en/v2.174.0/experiments/sagemaker.experiments.html) to track metrics from the Training Job. SageMaker Experiments will use the list of metric definitions to decide which metrics to track and how to parse them from the Training Job logs. For more information, check [Manage Machine Learning with Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) and the [SageMaker Experiments' SDK documentation](https://sagemaker.readthedocs.io/en/v2.174.0/experiments/sagemaker.experiments.html).\n",
    "\n",
    "Here are the environment variables we need to set on the traininng container:\n",
    "\n",
    "-   `COMET_API_KEY`: This is your [Comet](https://www.comet.com/site/?utm_source=svpino_course&utm_medium=partner&utm_content=github) API key.\n",
    "-   `COMET_PROJECT_NAME`: The name of the project where you want to track the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe82ae-6a2c-4461-bc83-bb52d8871e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    base_job_name=\"training\",\n",
    "    entry_point=\"script.py\",\n",
    "    source_dir=f\"{(CODE_FOLDER / 'training').as_posix()}\",\n",
    "    # SageMaker will pass these hyperparameters as arguments\n",
    "    # to the entry point of the training script.\n",
    "    hyperparameters={\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 32,\n",
    "    },\n",
    "    # SageMaker will create these environment variables on the\n",
    "    # Training Job instance.\n",
    "    environment={\n",
    "        \"COMET_API_KEY\": COMET_API_KEY,\n",
    "        \"COMET_PROJECT_NAME\": COMET_PROJECT_NAME,\n",
    "    },\n",
    "    # SageMaker will track these metrics as part of the experiment\n",
    "    # associated to this pipeline. The metric definitions tells\n",
    "    # SageMaker how to parse the values from the Training Job logs.\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "    ],\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    py_version=config[\"py_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d2b43-3bb5-4fe9-b3e4-cb8eb55c8a21",
   "metadata": {},
   "source": [
    "We can now create a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training). This Training Step will create a SageMaker Training Job in the background, run the training script, and upload the output to S3. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "This step will receive the train and validation split from the preprocessing step as inputs.\n",
    "\n",
    "Here, we are using three input channels, `train`, `validation`, and `pipeline`. SageMaker will automatically create an environment variable corresponding to each of these channels following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "-   `SM_CHANNEL_TRAIN`: This environment variable will contain the path to the training data coming from the preprocessing step.\n",
    "-   `SM_CHANNEL_VALIDATION`: This environment variable will contain the path to the validation data coming from the preprocessing step.\n",
    "-   `SM_CHANNEL_PIPELINE`: This environment variable will contain the path to the transformation pipeline that we saved in the preprocessing step.\n",
    "\n",
    "Notice that we are creating a function that we can later reuse to create a training step using a different estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4850c-83d6-4f4e-a813-d5a3f4bb7486",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "def create_training_step(estimator):\n",
    "    \"\"\"Create a SageMaker TrainingStep using the provided estimator.\"\"\"\n",
    "    return TrainingStep(\n",
    "        name=\"train-model\",\n",
    "        step_args=estimator.fit(\n",
    "            inputs={\n",
    "                \"train\": TrainingInput(\n",
    "                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"train\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"validation\": TrainingInput(\n",
    "                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"validation\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"pipeline\": TrainingInput(\n",
    "                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"model\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"application/tar+gzip\",\n",
    "                ),\n",
    "            },\n",
    "        ),\n",
    "        cache_config=cache_config,\n",
    "    )\n",
    "\n",
    "\n",
    "train_model_step = create_training_step(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcda131",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cac3d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session4_pipeline = Pipeline(\n",
    "    name=\"session4-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session4_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26e647",
   "metadata": {},
   "source": [
    "#### <font color = \"red\"> If you want to run the cell, **comment out** the line containing the <code>%%script</code> cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "session4_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23767878",
   "metadata": {},
   "source": [
    "## Session 5 - Custom Training Container\n",
    "\n",
    "This session creates a custom Docker image to train the model and have full control of the environment where the training script runs.\n",
    "\n",
    "For this example, we'll run the training script using [Keras 3](https://keras.io) with a [JAX](https://jax.readthedocs.io/en/latest/index.html) backend. Check [Adapting your own Docker container to work with SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-adapt-your-own.html) for more information about using your own Docker containers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877305d",
   "metadata": {},
   "source": [
    "### Step 1 - Preparing the Docker Image\n",
    "\n",
    "The first step is to copy the training script to a folder where we'll prepare the Docker image. We are going to reuse the training script we created before, since it's compatible with the latest version of Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###DB###\n",
    "# # Assuming CODE_FOLDER is defined as a Path object\n",
    "# training_dir = CODE_FOLDER / \"containers\" / \"training\"\n",
    "\n",
    "# # Check if the directory exists\n",
    "# if training_dir.is_dir():\n",
    "#     print(\"The 'training' directory already exists.\")\n",
    "# else:\n",
    "#     print(\"The 'training' directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "(CODE_FOLDER / \"containers\" / \"training\").mkdir(parents=True, exist_ok=True)\n",
    "shutil.copy2(\n",
    "    CODE_FOLDER / \"training\" / \"script.py\",\n",
    "    CODE_FOLDER / \"containers\" / \"training\" / \"train.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###DB###\n",
    "# # Assuming CODE_FOLDER is defined as a Path object\n",
    "# training_dir = CODE_FOLDER / \"containers\" / \"training\"\n",
    "\n",
    "# # Check if the directory exists\n",
    "# if training_dir.is_dir():\n",
    "#     print(\"The 'training' directory already exists.\")\n",
    "# else:\n",
    "#     print(\"The 'training' directory does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af356028",
   "metadata": {},
   "source": [
    "Since we are creating a new Docker image, we need to install the libraries we need in the training container. We'll use a `requirements.txt` file to install these libraries. Notice that we are installing `jax` to run it as our backend.\n",
    "\n",
    "The `sagemaker-training` library contains the common functionality necessary to create a container compatible with SageMaker and its Python SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa9250",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/containers/training/requirements.txt\n",
    "# | filename: requirements.txt\n",
    "# | code-line-numbers: true\n",
    "\n",
    "sagemaker-training\n",
    "packaging\n",
    "keras\n",
    "pandas\n",
    "scikit-learn\n",
    "comet_ml\n",
    "jax[cpu]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbed197",
   "metadata": {},
   "source": [
    "We can now create the Dockerfile containing the instructions to build the training image. Notice how this image will automatically run the `train.py` script when it starts.\n",
    "\n",
    "To use JAX as the backend for our model, we need to set the `KERAS_BACKEND` environment variable to `jax`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d473c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/containers/training/Dockerfile\n",
    "# | filename: Dockerfile\n",
    "# | code-line-numbers: true\n",
    "\n",
    "FROM python:3.10-slim\n",
    "\n",
    "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
    "    python3 \\\n",
    "    build-essential libssl-dev pkg-config libhdf5-dev\n",
    "\n",
    "# Let's install the required Python packages from \n",
    "# the requirements.txt file.\n",
    "COPY requirements.txt .\n",
    "RUN pip install --user --upgrade pip\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "# We are going to be running the training script\n",
    "# as the entrypoint of this container.\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "ENV SAGEMAKER_PROGRAM train.py\n",
    "\n",
    "# We want to use JAX as the backend for Keras.\n",
    "ENV KERAS_BACKEND=jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746dc0da",
   "metadata": {},
   "source": [
    "### Step 2 - Building the Docker Image\n",
    "\n",
    "We can now build the Docker image using the `docker build` command. We are going to define the name of this image using the `IMAGE_NAME` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"running in LOCAL_MODE: {LOCAL_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a06ac",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "IMAGE_NAME = \"keras-custom-training-container\"\n",
    "\n",
    "if not LOCAL_MODE:\n",
    "    # If we aren't running the code in Local Mode, we need\n",
    "    # to specify we want to build the Docker image for the\n",
    "    # linux/amd64 architecture before uploading it to ECR.\n",
    "    print(\"Building Docker image for linux/amd64 architecture...\")\n",
    "\n",
    "    !docker build --platform=\"linux/amd64\" -t $IMAGE_NAME \\\n",
    "        $CODE_FOLDER/containers/training/\n",
    "else:\n",
    "    # If we are running in Local Mode, we can use the\n",
    "    # default Docker build command.\n",
    "    print(\"Building Docker image for arm64 architecture...\")\n",
    "\n",
    "    !docker build -t $IMAGE_NAME \\\n",
    "        $CODE_FOLDER/containers/training/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56232bec",
   "metadata": {},
   "source": [
    "### Step 3 - Pushing Docker Image to ECR\n",
    "\n",
    "We can now push the Docker image to Amazon Elastic Container Registry (ECR). This is a fully-managed Docker container registry where we can manage Docker container images. This step is necessary to make the image available to SageMaker when running the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need LOCAL_MODE to be False to push to ECR\n",
    "print(f\"running in LOCAL_MODE: {LOCAL_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceede5e2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$LOCAL_MODE\" \"$IMAGE_NAME\"\n",
    "# | eval: false\n",
    "\n",
    "algorithm_name=$2\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration\n",
    "# (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "repository=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# We only want to push the Docker image to ECR if\n",
    "# we are not running in Local Mode.\n",
    "if [ $1 = \"False\" ]\n",
    "then\n",
    "    # Create the repository if it doesn't exist in ECR\n",
    "    aws ecr describe-repositories \\\n",
    "        --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "    if [ $? -ne 0 ]\n",
    "    then\n",
    "        aws ecr create-repository \\\n",
    "            --repository-name \"${algorithm_name}\" > /dev/null\n",
    "    fi\n",
    "\n",
    "    # Get the login command from ECR to run the\n",
    "    # Docker push command.\n",
    "    aws ecr get-login-password \\\n",
    "        --region ${region}|docker \\\n",
    "        login --username AWS --password-stdin ${repository}\n",
    "\n",
    "    # Push the Docker image to the ECR repository\n",
    "    docker tag ${algorithm_name} ${repository}\n",
    "    docker push ${repository}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413a387",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Training Step\n",
    "\n",
    "Let's now compute the name of the training image we'll use to run the Training Job.\n",
    "\n",
    "If we are running in `LOCAL_MODE`, we'll use the name of the image we built before (`IMAGE_NAME`). Otherwise, we'll use the name of the image we pushed to ECR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need LOCAL_MODE to be False to push to ECR\n",
    "print(f\"running in LOCAL_MODE: {LOCAL_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "tag = \":latest\"\n",
    "\n",
    "uri_suffix = \"amazonaws.com\"\n",
    "if region in [\"cn-north-1\", \"cn-northwest-1\"]:\n",
    "    uri_suffix = \"amazonaws.com.cn\"\n",
    "\n",
    "training_container_image = (\n",
    "    IMAGE_NAME\n",
    "    if LOCAL_MODE\n",
    "    else (f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{IMAGE_NAME}:latest\")\n",
    ")\n",
    "\n",
    "training_container_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4eaf1",
   "metadata": {},
   "source": [
    "We can now create an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) and a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) using the function we created before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e17204",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "keras_estimator = Estimator(\n",
    "    image_uri=training_container_image,\n",
    "    instance_count=1,\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "keras_train_model_step = create_training_step(keras_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212693e",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86056197",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session5_pipeline = Pipeline(\n",
    "    name=\"session5-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        # This time we want to use the new training step\n",
    "        # we created using the custom Docker image.\n",
    "        keras_train_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session5_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b53801",
   "metadata": {},
   "source": [
    "#### <font color = \"red\">If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "session5_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef68a77",
   "metadata": {},
   "source": [
    "## Session 6 - Tuning the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [step to tune the model](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning) using a Hyperparameter Tuning Job.\n",
    "\n",
    "<a href=\"images/tuning-step.png\" target=\"_blank\"> <img src=\"images/tuning-step.png\" alt=\"High-level overview of the Tuning Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96707b5",
   "metadata": {},
   "source": [
    "### Step 1 - Enabling Tuning\n",
    "\n",
    "Since we could use the Training of the Tuning Step to create a model, we'll define a constant to indicate which approach we want to run. Notice that the Tuning Step is not supported in Local Mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29f485",
   "metadata": {},
   "source": [
    "#### <font color = \"red\">Note: Tuning step not available for LOCAL_MODE</font> ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"running in LOCAL_MODE: {LOCAL_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variable USE_TUNING_STEP to True if not running in LOCAL_MODE\n",
    "# Toggle_Tuning_On = True\n",
    "Toggle_Tuning_On = False\n",
    "USE_TUNING_STEP = Toggle_Tuning_On and not LOCAL_MODE\n",
    "print(f\"USE_TUNING_STEP: {USE_TUNING_STEP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814e258-c633-4e9a-85c5-6ed0f168b503",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up a Tuning Step\n",
    "\n",
    "Let's now create a [Tuning Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning). This Tuning Step will create a SageMaker Hyperparameter Tuning Job in the background and use the training script to train different model variants and choose the best one. Check the [TuningStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "The Tuning Step requires a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) reference to configure the Hyperparameter Tuning Job.\n",
    "\n",
    "Here is the configuration that we'll use to find the best model:\n",
    "\n",
    "1. `objective_metric_name`: This is the name of the metric the tuner will use to determine the best model.\n",
    "2. `objective_type`: This is the objective of the tuner. It specifies whether it should minimize the metric or maximize it. In this example, since we are using the validation accuracy of the model, we want the objective to be \"Maximize.\" If we were using the loss of the model, we would set the objective to \"Minimize.\"\n",
    "3. `metric_definitions`: Defines how the tuner will determine the metric's value by looking at the output logs of the training process.\n",
    "\n",
    "The tuner expects the list of the hyperparameters you want to explore. You can use subclasses of the [Parameter](https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html#sagemaker.parameter.ParameterRange) class to specify different types of hyperparameters. This example explores different values for the `epochs` hyperparameter.\n",
    "\n",
    "Finally, you can control the number of jobs and how many of them will run in parallel using the following two arguments:\n",
    "\n",
    "-   `max_jobs`: Defines the maximum total number of training jobs to start for the hyperparameter tuning job.\n",
    "-   `max_parallel_jobs`: Defines the maximum number of parallel training jobs to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c82750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import IntegerParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name=\"val_accuracy\",\n",
    "    objective_type=\"Maximize\",\n",
    "    hyperparameter_ranges={\n",
    "        \"epochs\": IntegerParameter(10, 50),\n",
    "    },\n",
    "    metric_definitions=[{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2abc2",
   "metadata": {},
   "source": [
    "We can now create the Tuning Step using the tuner we configured before. SageMaker will create a Hyperparameter Tuning Job in the background and use the training script to train different model variants and choose the best one.\n",
    "\n",
    "<a href=\"images/tuning-job.png\" target=\"_blank\"> <img src=\"images/tuning-job.png\" alt=\"High-level overview of SageMaker's Hyperparameter Tuning Jobs\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ff2e5-ed28-445b-bc03-4e996ec2286f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "tune_model_step = TuningStep(\n",
    "    name=\"tune-model\",\n",
    "    step_args=tuner.fit(\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"pipeline\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"model\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"application/tar+gzip\",\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babe38c-1682-42d2-8442-101d17aa89b5",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799ab39-fcae-41f4-a68b-85ab71b3ba9a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session6_pipeline = Pipeline(\n",
    "    name=\"session6-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session6_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7527c4",
   "metadata": {},
   "source": [
    "#### <font color = \"red\"> If you want to run the cell, **comment out** the line containing the <code>%%script</code> cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32779b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "session6_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d40fe8-ba74-4c12-9555-d8ea33d1c8b4",
   "metadata": {},
   "source": [
    "## Session 7 - Evaluating the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to evaluate the model using the holdout set we created during the preprocessing step.\n",
    "\n",
    "<a href=\"images/evaluation-step.png\" target=\"_blank\"> <img src=\"images/evaluation-step.png\" alt=\"High-level overview of the Evaluation Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa9691-f49f-48af-b272-3d4d17563b01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1 - Creating the Evaluation Script\n",
    "\n",
    "We'll use a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) to execute the evaluation script.\n",
    "\n",
    "This script is responsible for loading the model we created and evaluating it on the test set. Before finishing, this script will generate an evaluation report of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb3406",
   "metadata": {},
   "source": [
    "We will store the script in a folder called `evaluation` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"evaluation\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccf926",
   "metadata": {},
   "source": [
    "We can now create the script inside the folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation/script.py\n",
    "# | filename: script.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test[X_test.columns[-1]]\n",
    "    X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "    # Let's now extract the model package so we can load\n",
    "    # it in memory.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "\n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "\n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "    # Let's create an evaluation report using the model accuracy.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\"value\": accuracy},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"/opt/ml/processing/model/\",\n",
    "        test_path=\"/opt/ml/processing/test/\",\n",
    "        output_path=\"/opt/ml/processing/evaluation/\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc79a0-adfd-4ce9-8580-5cd228c3c2d9",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%ipytest -s\n",
    "# | code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "\n",
    "from processing.script import preprocess\n",
    "from training.script import train\n",
    "from evaluation.script import evaluate\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "\n",
    "    directory = Path(directory)\n",
    "\n",
    "    preprocess(base_directory=directory)\n",
    "\n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\",\n",
    "        validation_path=directory / \"validation\",\n",
    "        pipeline_path=directory / \"model\",\n",
    "        experiment=None,\n",
    "        epochs=1,\n",
    "    )\n",
    "\n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model\" / \"001\", arcname=\"001\")\n",
    "\n",
    "    evaluate(\n",
    "        model_path=directory,\n",
    "        test_path=directory / \"test\",\n",
    "        output_path=directory / \"evaluation\",\n",
    "    )\n",
    "\n",
    "    yield directory / \"evaluation\"\n",
    "\n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_evaluate_generates_evaluation_report(directory):\n",
    "    output = os.listdir(directory)\n",
    "    assert \"evaluation.json\" in output\n",
    "\n",
    "\n",
    "def test_evaluation_report_contains_accuracy(directory):\n",
    "    with open(directory / \"evaluation.json\", \"r\") as file:\n",
    "        report = json.load(file)\n",
    "\n",
    "    assert \"metrics\" in report\n",
    "    assert \"accuracy\" in report[\"metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627a263",
   "metadata": {},
   "source": [
    "### Step 2 - Referencing the Model Assets\n",
    "\n",
    "One of the inputs to the evaluation step is the model coming from the Training or the Tuning step. We can use the `USE_TUNING_STEP` flag to determine whether we created the model using a Training Step or a Tuning Step.\n",
    "\n",
    "In case we are using the Tuning Step, we can use the [TuningStep.get_top_model_s3_uri()](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep.get_top_model_s3_uri) function to get the model assets from the top performing training job of the Hyperparameter Tuning Job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"USE_TUNING_STEP: {USE_TUNING_STEP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using training\n",
    "model_assets = train_model_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "if USE_TUNING_STEP:\n",
    "    model_assets = tune_model_step.get_top_model_s3_uri(\n",
    "        top_k=0,\n",
    "        s3_bucket=config[\"session\"].default_bucket(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc98283",
   "metadata": {},
   "source": [
    "### Step 3 - Mapping the Output to a Property File\n",
    "\n",
    "SageMaker supports mapping outputs from a Processing Step to property files. This is useful when we want to access a specific property from the pipeline.\n",
    "\n",
    "We'll map the evaluation report to a property file. Check [How to Build and Manage Property Files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1109a-6c26-4464-8338-94960729d212",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Evaluation Step\n",
    "\n",
    "To run the evaluation script, we will use a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) configured with a [TensorFlowProcessor](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks-tensorflow.html) because the script needs access to TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdff07f",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlowProcessor\n",
    "\n",
    "evaluation_processor = TensorFlowProcessor(\n",
    "    base_job_name=\"evaluation-processor\",\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    py_version=config[\"py_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4dbc0e",
   "metadata": {},
   "source": [
    "We are now ready to define the [Processing Step](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) that will run the evaluation script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48139a07-5c8e-4bc6-b666-bf9531f7f520",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "evaluate_model_step = ProcessingStep(\n",
    "    name=\"evaluate-model\",\n",
    "    step_args=evaluation_processor.run(\n",
    "        code=f\"{(CODE_FOLDER / 'evaluation' / 'script.py').as_posix()}\",\n",
    "        inputs=[\n",
    "            # The first input is the test split that we generated on\n",
    "            # the first step of the pipeline when we split and\n",
    "            # transformed the data.\n",
    "            ProcessingInput(\n",
    "                source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "            # The second input is the model that we generated on\n",
    "            # the Training or Tunning Step.\n",
    "            ProcessingInput(\n",
    "                source=model_assets,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            # The output is the evaluation report that we generated\n",
    "            # in the evaluation script.\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\",\n",
    "                source=\"/opt/ml/processing/evaluation\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30413e8d",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1ab1f",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session7_pipeline = Pipeline(\n",
    "    name=\"session7-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session7_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cb64a",
   "metadata": {},
   "source": [
    "#### <font color = \"red\"> If you want to run the cell, **comment out** the line containing the <code>%%script</code> cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "session7_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3989b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031af83a",
   "metadata": {},
   "source": [
    "## Session 8 - Registering the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to [register the model](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-version.html) in the [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html).\n",
    "\n",
    "<a href=\"images/registration-step.png\" target=\"_blank\"> <img src=\"images/registration-step.png\" alt=\"High-level overview of the Registration Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1d882",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Model Package Group\n",
    "\n",
    "First, let's define the name of the group where we'll register the model. The Model Registry uses groups to organize the versions of a model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_MODEL_PACKAGE_GROUP = \"basic-penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bcad3b",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Model\n",
    "\n",
    "Let's now create the model that we'll register in the Model Registry. The model we trained uses TensorFlow, so we can use the built-in [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-model) class to create an instance of the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "tensorflow_model = TensorFlowModel(\n",
    "    model_data=model_assets,\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a532c",
   "metadata": {},
   "source": [
    "### Step 3 - Configuring Model Metrics\n",
    "\n",
    "When we register a model in the Model Registry, we can attach relevant metadata to it. We'll use the evaluation report we generated during the evaluation step to populate the [metrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) of this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                evaluate_model_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"evaluation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb3e51",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "We can use a [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) to register the model. Check the [ModelStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.model_step.ModelStep) SageMaker's SDK documentation for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9773a4a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "\n",
    "def create_registration_step(\n",
    "    model,\n",
    "    model_package_group_name,\n",
    "    approval_status=\"Approved\",\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    model_metrics=None,\n",
    "    drift_check_baselines=None,\n",
    "):\n",
    "    \"\"\"Create a Registration Step using the supplied parameters.\"\"\"\n",
    "    return ModelStep(\n",
    "        name=\"register\",\n",
    "        step_args=model.register(\n",
    "            model_package_group_name=model_package_group_name,\n",
    "            approval_status=approval_status,\n",
    "            model_metrics=model_metrics,\n",
    "            drift_check_baselines=drift_check_baselines,\n",
    "            content_types=content_types,\n",
    "            response_types=response_types,\n",
    "            inference_instances=[config[\"instance_type\"]],\n",
    "            transform_instances=[config[\"instance_type\"]],\n",
    "            framework_version=config[\"framework_version\"],\n",
    "            domain=\"MACHINE_LEARNING\",\n",
    "            task=\"CLASSIFICATION\",\n",
    "            framework=\"TENSORFLOW\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "register_model_step = create_registration_step(\n",
    "    tensorflow_model,\n",
    "    BASIC_MODEL_PACKAGE_GROUP,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0276efc",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09cc85",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session8_pipeline = Pipeline(\n",
    "    name=\"session8-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "        register_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session8_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3274db6",
   "metadata": {},
   "source": [
    "## Session 9 - Conditional Registration\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a condition to register the model only if its accuracy is above a predefined threshold.\n",
    "\n",
    "Here's a high-level overview of the Condition Step:\n",
    "\n",
    "<a href=\"images/condition-step.png\" target=\"_blank\"> <img src=\"images/condition-step.png\" alt=\"High-level overview of the Condition Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a51f95",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Accuracy Threshold\n",
    "\n",
    "Let's define a new [Pipeline Parameter](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) to specify the minimum accuracy that the model should reach for it to be registered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745486b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterFloat\n",
    "\n",
    "accuracy_threshold = ParameterFloat(name=\"accuracy_threshold\", default_value=0.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c959c94",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up a Fail Step\n",
    "\n",
    "If the model's accuracy is not greater than or equal to our threshold, we will send the pipeline to a [Fail Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-fail) with the appropriate error message. Check the [FailStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.fail_step.FailStep) SageMaker's SDK documentation for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4431bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \",\n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\",\n",
    "            accuracy_threshold,\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47764f9",
   "metadata": {},
   "source": [
    "### Step 3 - Defining the Condition\n",
    "\n",
    "We can use a [ConditionGreaterThanOrEqualTo](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.conditions.ConditionGreaterThanOrEqualTo) condition to compare the model's accuracy with the threshold. Look at the [Conditions](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html#conditions) section in the documentation for more information about the types of supported conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluate_model_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=accuracy_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c110f7-fe72-4db8-9d06-cfb9a0f2bfbd",
   "metadata": {},
   "source": [
    "### Step 4 - Setting up the Condition Step\n",
    "\n",
    "Let's now use a [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) together with the evaluation report we generated to determine whether the model's accuracy is above the threshold:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2a2b1-6711-4266-95d8-d2aebd52e199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309b8fa-f03e-4959-853f-dc2416f82bdd",
   "metadata": {},
   "source": [
    "### Step 5 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session9_pipeline = Pipeline(\n",
    "    name=\"session9-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session9_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176c6fd",
   "metadata": {},
   "source": [
    "## Session 10 - Serving the Model\n",
    "\n",
    "This session builds a simple [Flask](https://flask.palletsprojects.com/) application to serve the model.\n",
    "\n",
    "<a href=\"images/deploying-flask.png\" target=\"_blank\"> <img src=\"images/deploying-flask.png\" alt=\"High-level overview of deploying a model using a Flask wrapper\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Keep in mind that, while good for development and testing, this is not the best approach for production systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6e55d",
   "metadata": {},
   "source": [
    "### Step 1 - Retrieving List of Approved Models\n",
    "\n",
    "We want to serve the latest approved model from the Model Registry. We can use the [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) API to get this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67726d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.list_model_packages(\n",
    "    ModelPackageGroupName=BASIC_MODEL_PACKAGE_GROUP,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    SortBy=\"CreationTime\",\n",
    "    MaxResults=1,\n",
    ")\n",
    "\n",
    "package = (\n",
    "    response[\"ModelPackageSummaryList\"][0]\n",
    "    if response[\"ModelPackageSummaryList\"]\n",
    "    else None\n",
    ")\n",
    "\n",
    "package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca789bd2",
   "metadata": {},
   "source": [
    "### Step 2 - Downloading the Model\n",
    "\n",
    "Let's now download the model assets from the location specified in the Model Registry to your local environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2891178",
   "metadata": {},
   "source": [
    "We will store this model in a folder called `serving`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e94adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"serving\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c01cc",
   "metadata": {},
   "source": [
    "Let's now download the model assets into the folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "if package:\n",
    "    response = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=package[\"ModelPackageArn\"],\n",
    "    )\n",
    "\n",
    "    model_data = response[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]\n",
    "    S3Downloader.download(model_data, (CODE_FOLDER / \"serving\").as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f2e42",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Serving Script\n",
    "\n",
    "Let's now write a simple Flask script to serve the model.\n",
    "\n",
    "When this application receives the first request, it will unpack and load the model into memory. From there, it will use the model to make predictions on the incoming requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a0e74",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/serving/app.py\n",
    "# | filename: app.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import tarfile\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "MODEL_PATH = Path(__file__).parent\n",
    "\n",
    "\n",
    "class Model:\n",
    "    model = None\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Extracts the model package and loads the model in memory\n",
    "        if it hasn't been loaded yet.\n",
    "        \"\"\"\n",
    "        # We want to load the model only if it is not loaded yet.\n",
    "        if not Model.model:\n",
    "            # Before we load the model, we need to extract it in\n",
    "            # a temporal directory.\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as directory:\n",
    "                with tarfile.open(MODEL_PATH / \"model.tar.gz\") as tar:\n",
    "                    tar.extractall(path=directory)\n",
    "\n",
    "                Model.model = keras.models.load_model(Path(directory) / \"001\")\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Generates predictions for the supplied data.\n",
    "        \"\"\"\n",
    "        self.load()\n",
    "        return Model.model.predict(data)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = Model()\n",
    "\n",
    "\n",
    "@app.route(\"/predict/\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.data.decode(\"utf-8\")\n",
    "\n",
    "    data = np.array(data.split(\",\")).astype(np.float32)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "\n",
    "    predictions = model.predict(data=[data])\n",
    "\n",
    "    prediction = int(np.argmax(predictions[0], axis=-1))\n",
    "    confidence = float(predictions[0][prediction])\n",
    "\n",
    "    return jsonify({\"prediction\": prediction, \"confidence\": confidence})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4d828",
   "metadata": {},
   "source": [
    "### Step 4 - Running the Flask Application\n",
    "\n",
    "We can now run the Flask application to serve the model from a terminal using the following command:\n",
    "\n",
    "```bash\n",
    "$ flask --app program/code/serving/app.py --debug run --host=0.0.0.0 --port=4242\n",
    "```\n",
    "\n",
    "After the server is running, you can send a POST request to the server to get a prediction. Here is an example using the `curl` command:\n",
    "\n",
    "```bash\n",
    "$ curl --location --request POST 'http://localhost:4242/predict' \\\n",
    "    --header 'Content-Type: text/plain' \\\n",
    "    --data-raw '0.6569590202313976, -1.0813829646495108, 1.2097102831892812, 0.9226343641317372, 1.0, 0.0, 0.0'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a05e63",
   "metadata": {},
   "source": [
    "## Session 11 - Deploying the Model\n",
    "\n",
    "This session deploys the model from the Model Registry to an endpoint. We'll do it manually, using the SageMaker SDK. Check [Deploy to a SageMaker Endpoint](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#deploy-to-a-sagemaker-endpoint) for more information about deploying a model to an endpoint.\n",
    "\n",
    "<a href=\"images/deploying-model.png\" target=\"_blank\"> <img src=\"images/deploying-model.png\" alt=\"High-level overview of deploying a model to a SageMaker endpoint\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9b989",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Endpoint Name\n",
    "\n",
    "Let's start by defining the name of the endpoint where we'll deploy the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "ENDPOINT = \"penguins-endpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af752269",
   "metadata": {},
   "source": [
    "### Step 2 - Creating a Model Package\n",
    "\n",
    "To deploy a model using the SageMaker's Python SDK, we need to create a [Model Package](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage) using the ARN of the model from the Model Registry. Remember we got the ARN of the latest approved model in the previous section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee516e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "if package:\n",
    "    model_package = ModelPackage(\n",
    "        model_package_arn=package[\"ModelPackageArn\"],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "    print(package[\"ModelPackageArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3119b48-2ddf-40b5-9ac0-680073a53d06",
   "metadata": {},
   "source": [
    "### Step 3 - Deploying the Model\n",
    "\n",
    "Let's now deploy the model to an endpoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2ed9f",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8852d5-818a-406c-944d-30bf6de90288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "model_package.deploy(\n",
    "    endpoint_name=ENDPOINT,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=config[\"instance_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7a725",
   "metadata": {},
   "source": [
    "### Step 4 - Testing the Endpoint\n",
    "\n",
    "After deploying the model, we can test the endpoint to make sure it works.\n",
    "\n",
    "Each line of the payload we'll send to the endpoint contains the information of a penguin. Notice the model expects data that's already transformed. We can't provide the original data from our dataset because the model we registered will not work with it.\n",
    "\n",
    "The endpoint will return the predictions for each of these lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7da291",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"\"\"\n",
    "0.6569590202313976,-1.0813829646495108,1.2097102831892812,0.9226343641317372,1.0,0.0,0.0\n",
    "-0.7751048801481084,0.8822689351285553,-1.2168066120762704,0.9226343641317372,0.0,1.0,0.0\n",
    "-0.837387834894918,0.3386660813829646,-0.26237731892812,-1.92351941317372,0.0,0.0,1.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcfffa-0ba6-4ad8-8b4f-1ea19b35a22f",
   "metadata": {},
   "source": [
    "Let's send the payload to the endpoint and print its response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0817a25e-8224-4911-830b-d659e7458b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(endpoint_name=ENDPOINT)\n",
    "\n",
    "try:\n",
    "    response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    response = json.loads(response.decode(\"utf-8\"))\n",
    "\n",
    "    print(json.dumps(response, indent=2))\n",
    "    print(f\"\\nSpecies: {np.argmax(response['predictions'], axis=1)}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab1884",
   "metadata": {},
   "source": [
    "## Session 12 - Deploying From the Pipeline\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to automatically deploy the model to an endpoint.\n",
    "\n",
    "We'll use a [Lambda Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda) to create an endpoint and deploy the model.\n",
    "\n",
    "Here's a high-level overview of the Deploy Step:\n",
    "\n",
    "<a href=\"images/deploy-step.png\" target=\"_blank\"> <img src=\"images/deploy-step.png\" alt=\"High-level overview of the Deploy Step\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb6753",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Data Capture Settings\n",
    "\n",
    "We want to enable [Data Capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html) as part of the endpoint configuration. With Data Capture we can record the inputs and outputs of the endpoint to use them later for monitoring the model. We need to configuration settings to enable Data Capture:\n",
    "\n",
    "-   `DATA_CAPTURE_PERCENTAGE`: Represents the percentage of traffic that we want to capture.\n",
    "-   `DATA_CAPTURE_DESTINATION`: Specifies the S3 location where we want to store the captured data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CAPTURE_PERCENTAGE = 100\n",
    "DATA_CAPTURE_DESTINATION = f\"{S3_LOCATION}/monitoring/data-capture\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686ba99",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up the Lambda Function\n",
    "\n",
    "Let's start by writing a Lambda function that takes the model information and deploys it to an endpoint.\n",
    "\n",
    "There are three components that make up a SageMaker endpoint:\n",
    "\n",
    "<a href=\"images/endpoint.png\" target=\"_blank\"> <img src=\"images/endpoint.png\" alt=\"An overview of the three components of an Endpoint\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48c7bd",
   "metadata": {},
   "source": [
    "We'll store the code of the function in a folder called `lambda`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7630ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"lambda\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f35b1",
   "metadata": {},
   "source": [
    "Let's now write the code of the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b651af",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/lambda/lambda.py\n",
    "# | filename: lambda.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # If we are calling this function from EventBridge,\n",
    "    # we need to extract the model package ARN and the\n",
    "    # approval status from the event details. If we are\n",
    "    # calling this function from the pipeline, we can\n",
    "    # assume the model is approved and we can get the\n",
    "    # model package ARN as a direct parameter.\n",
    "    if \"detail\" in event:\n",
    "        model_package_arn = event[\"detail\"][\"ModelPackageArn\"]\n",
    "        approval_status = event[\"detail\"][\"ModelApprovalStatus\"]\n",
    "    else:\n",
    "        model_package_arn = event[\"model_package_arn\"]\n",
    "        approval_status = \"Approved\"\n",
    "\n",
    "    print(f\"Model: {model_package_arn}\")\n",
    "    print(f\"Approval status: {approval_status}\")\n",
    "\n",
    "    if approval_status != \"Approved\":\n",
    "        response = {\n",
    "            \"message\": \"Skipping deployment.\",\n",
    "            \"approval_status\": approval_status,\n",
    "        }\n",
    "\n",
    "        print(response)\n",
    "        return {\"statusCode\": 200, \"body\": json.dumps(response)}\n",
    "\n",
    "    endpoint_name = os.environ[\"ENDPOINT\"]\n",
    "    data_capture_percentage = int(os.environ[\"DATA_CAPTURE_PERCENTAGE\"])\n",
    "    data_capture_destination = os.environ[\"DATA_CAPTURE_DESTINATION\"]\n",
    "    role = os.environ[\"ROLE\"]\n",
    "\n",
    "    timestamp = time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "    model_name = f\"{endpoint_name}-model-{timestamp}\"\n",
    "    endpoint_config_name = f\"{endpoint_name}-config-{timestamp}\"\n",
    "\n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name,\n",
    "        ExecutionRoleArn=role,\n",
    "        Containers=[{\"ModelPackageName\": model_package_arn}],\n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        # We can enable Data Capture to record the inputs and outputs\n",
    "        # of the endpoint to use them later for monitoring the model.\n",
    "        DataCaptureConfig={\n",
    "            \"EnableCapture\": True,\n",
    "            \"InitialSamplingPercentage\": data_capture_percentage,\n",
    "            \"DestinationS3Uri\": data_capture_destination,\n",
    "            \"CaptureOptions\": [\n",
    "                {\"CaptureMode\": \"Input\"},\n",
    "                {\"CaptureMode\": \"Output\"},\n",
    "            ],\n",
    "            \"CaptureContentTypeHeader\": {\n",
    "                \"CsvContentTypes\": [\"text/csv\", \"application/octect-stream\"],\n",
    "                \"JsonContentTypes\": [\"application/json\", \"application/octect-stream\"],\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    response = sagemaker.list_endpoints(NameContains=endpoint_name, MaxResults=1)\n",
    "\n",
    "    if len(response[\"Endpoints\"]) == 0:\n",
    "        # If the endpoint doesn't exist, let's create it.\n",
    "        sagemaker.create_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_config_name,\n",
    "        )\n",
    "    else:\n",
    "        # If the endpoint already exists, let's update it with the\n",
    "        # new configuration.\n",
    "        sagemaker.update_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_config_name,\n",
    "        )\n",
    "\n",
    "    return {\"statusCode\": 200, \"body\": json.dumps(\"Endpoint deployed successfully\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601027a",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up Lambda Permissions\n",
    "\n",
    "We need to ensure our Lambda function has permission to interact with SageMaker, so let's create a new role with the appropriate permissions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d0370",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "lambda_role_name = \"lambda-deployment-role\"\n",
    "lambda_role_arn = None\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=lambda_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"],\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "        Description=\"Lambda Endpoint Deployment\",\n",
    "    )\n",
    "\n",
    "    lambda_role_arn = response[\"Role\"][\"Arn\"]\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\",\n",
    "        RoleName=lambda_role_name,\n",
    "    )\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\",\n",
    "        RoleName=lambda_role_name,\n",
    "    )\n",
    "\n",
    "    print(f'Role \"{lambda_role_name}\" created with ARN \"{lambda_role_arn}\".')\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    response = iam_client.get_role(RoleName=lambda_role_name)\n",
    "    lambda_role_arn = response[\"Role\"][\"Arn\"]\n",
    "    print(f'Role \"{lambda_role_name}\" already exists with ARN \"{lambda_role_arn}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f81794",
   "metadata": {},
   "source": [
    "### Step 4 - Creating the Lambda Function\n",
    "\n",
    "Let's now create the Lambda function in AWS. We'll pass the configuration settings we defined before as environment variables to the Lambda function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a742974",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "deploy_lambda_fn = Lambda(\n",
    "    function_name=\"deployment_fn\",\n",
    "    execution_role_arn=lambda_role_arn,\n",
    "    script=(CODE_FOLDER / \"lambda\" / \"lambda.py\").as_posix(),\n",
    "    handler=\"lambda.lambda_handler\",\n",
    "    timeout=600,\n",
    "    session=sagemaker_session,\n",
    "    runtime=\"python3.11\",\n",
    "    environment={\n",
    "        \"Variables\": {\n",
    "            \"ENDPOINT\": ENDPOINT,\n",
    "            \"DATA_CAPTURE_DESTINATION\": DATA_CAPTURE_DESTINATION,\n",
    "            \"DATA_CAPTURE_PERCENTAGE\": str(DATA_CAPTURE_PERCENTAGE),\n",
    "            \"ROLE\": role,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "deploy_lambda_fn_response = deploy_lambda_fn.upsert()\n",
    "deploy_lambda_fn_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c806e",
   "metadata": {},
   "source": [
    "### Step 5 - Setting up the Lambda Step\n",
    "\n",
    "We can now define the [Lambda Step](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) that will run the function to deploy the model. We'll do this in a function that we can reuse later.\n",
    "\n",
    "This step will send the model package ARN we want to deploy to the Lambda function as an input parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "\n",
    "\n",
    "def create_deployment_step(register_model_step):\n",
    "    \"\"\"Create a Deploy Step using the supplied parameters.\"\"\"\n",
    "    return LambdaStep(\n",
    "        name=\"deploy\",\n",
    "        lambda_func=deploy_lambda_fn,\n",
    "        inputs={\n",
    "            \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "deploy_step = create_deployment_step(register_model_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2b11e",
   "metadata": {},
   "source": [
    "### Step 6 - Modifying the Condition Step\n",
    "\n",
    "We need to modify the [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to include the new deployment step. If the condition succeeds, we will register and deploy the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step, deploy_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951be04",
   "metadata": {},
   "source": [
    "### Step 7 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86577a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session12_pipeline = Pipeline(\n",
    "    name=\"session12-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session12_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddc94b",
   "metadata": {},
   "source": [
    "### Step 8 - Testing the Endpoint\n",
    "\n",
    "Let's test the endpoint to make sure it works.\n",
    "\n",
    "The `wait_for_endpoint` function will wait until the endpoint is ready to receive requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_endpoint():\n",
    "    \"\"\"Wait for the endpoint to come in service.\"\"\"\n",
    "    waiter = sagemaker_client.get_waiter(\"endpoint_in_service\")\n",
    "    waiter.wait(EndpointName=ENDPOINT, WaiterConfig={\"Delay\": 10, \"MaxAttempts\": 30})\n",
    "\n",
    "\n",
    "payload = \"0.6569590202313976,-1.0813829646495108,1.2097102831892812,0.9226343641317372,1.0,0.0,0.0\"  # noqa: E501\n",
    "\n",
    "\n",
    "try:\n",
    "    wait_for_endpoint()\n",
    "\n",
    "    predictor = Predictor(endpoint_name=ENDPOINT)\n",
    "\n",
    "    response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    response = json.loads(response.decode(\"utf-8\"))\n",
    "\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c31653",
   "metadata": {},
   "source": [
    "## Session 13 - Deploying From an Event\n",
    "\n",
    "This session modifies the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) to register the model with `PendingManualApproval` status and deploys it whenever its status changes to `Approved`.\n",
    "\n",
    "<a href=\"images/deploying-from-event.png\" target=\"_blank\"> <img src=\"images/deploying-from-event.png\" alt=\"High-level overview of deploying a model using EventBridge\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We will use [Amazon EventBridge](https://aws.amazon.com/pm/eventbridge/) to trigger a Lambda function that will deploy the model whenever its status changes from \"PendingManualApproval\" to \"Approved.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ad7d3",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring the Model Package Group\n",
    "\n",
    "We need to define the name of a new group where we'll register models with `PendingManualApproval` status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96751e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "PENDING_MODEL_PACKAGE_GROUP = \"pending-penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdfb284",
   "metadata": {},
   "source": [
    "### Step 2 - Setting Up EventBridge\n",
    "\n",
    "We can now create an EventBridge rule that triggers the deployment process whenever a model approval status becomes `Approved`. To do this, let's define the event pattern that will trigger the deployment process. Check [Model package state change](https://docs.aws.amazon.com/sagemaker/latest/dg/automating-sagemaker-with-eventbridge.html#eventbridge-model-package) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_pattern = f\"\"\"\n",
    "{{\n",
    "  \"source\": [\"aws.sagemaker\"],\n",
    "  \"detail-type\": [\"SageMaker Model Package State Change\"],\n",
    "  \"detail\": {{\n",
    "    \"ModelPackageGroupName\": [\"{PENDING_MODEL_PACKAGE_GROUP}\"],\n",
    "    \"ModelApprovalStatus\": [\"Approved\"]\n",
    "  }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c4908",
   "metadata": {},
   "source": [
    "Let's now create the EventBridge rule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f294bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_name = \"PendingModelApprovedRule\"\n",
    "\n",
    "events_client = boto3.client(\"events\")\n",
    "rule_response = events_client.put_rule(\n",
    "    Name=rule_name,\n",
    "    EventPattern=event_pattern,\n",
    "    State=\"ENABLED\",\n",
    "    RoleArn=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c2148",
   "metadata": {},
   "source": [
    "Now, we need to define the target of the rule. The target will trigger whenever the rule matches an event. In this case, we want to trigger the Lambda function we created before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = events_client.put_targets(\n",
    "    Rule=rule_name,\n",
    "    Targets=[\n",
    "        {\n",
    "            \"Id\": \"1\",\n",
    "            \"Arn\": deploy_lambda_fn_response[\"FunctionArn\"],\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22f63b",
   "metadata": {},
   "source": [
    "### Step 3 - Configuring the Lambda Permissions\n",
    "\n",
    "Finally, we need to give the Lambda function permissions to be triggered by the EventBridge rule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32302639",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_function_name = deploy_lambda_fn_response[\"FunctionName\"]\n",
    "lambda_client = boto3.client(\"lambda\")\n",
    "\n",
    "try:\n",
    "    response = lambda_client.add_permission(\n",
    "        Action=\"lambda:InvokeFunction\",\n",
    "        FunctionName=lambda_function_name,\n",
    "        Principal=\"events.amazonaws.com\",\n",
    "        SourceArn=rule_response[\"RuleArn\"],\n",
    "        StatementId=\"EventBridge\",\n",
    "    )\n",
    "except lambda_client.exceptions.ResourceConflictException:\n",
    "    print(f'Function \"{lambda_function_name}\" already has the specified permission.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a12be",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "We need to modify the [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) to register the model using `PendingManualApproval` status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18adeb93",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "register_model_step = create_registration_step(\n",
    "    tensorflow_model,\n",
    "    PENDING_MODEL_PACKAGE_GROUP,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34e825",
   "metadata": {},
   "source": [
    "### Step 5 - Modifying the Condition Step\n",
    "\n",
    "Let's modify the [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to include the new registration step. If the condition succeeds, we will register the model with `PendingManualApproval` status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a5a5d",
   "metadata": {},
   "source": [
    "### Step 6 - Creating the Pipeline\n",
    "\n",
    "Let's define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c22b2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session13_pipeline = Pipeline(\n",
    "    name=\"session13-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session13_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf1f02",
   "metadata": {},
   "source": [
    "## Session 14 - Building an Inference Pipeline\n",
    "\n",
    "This session creates an inference pipeline to control the data that goes in and comes out of the endpoint.\n",
    "\n",
    "Deploying the model we trained directly to an endpoint doesn't lets us control the data that goes in and comes out of the endpoint. The TensorFlow model we trained requires transformed data, which makes it useless to other applications:\n",
    "\n",
    "<a href=\"images/basic-model.png\" target=\"_blank\"> <img src=\"images/basic-model.png\" alt=\"Basic Model\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "To fix this, we can create an Inference Pipeline using SageMaker to control the data that goes in and comes out of the endpoint.\n",
    "\n",
    "Our inference pipeline will have three components:\n",
    "\n",
    "1. A preprocessing component that will transform the input data into the format the model expects.\n",
    "2. The TensorFlow model.\n",
    "3. A postprocessing component that will transform the output of the model into a human-readable format.\n",
    "\n",
    "<a href=\"images/inference-pipeline.png\" target=\"_blank\"> <img src=\"images/inference-pipeline.png\" alt=\"Inference pipeline\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "We want our endpoint to handle unprocessed data in CSV and JSON format and return the penguin's species. Here is an example of the payload input we want the endpoint to support:\n",
    "\n",
    "```{json}\n",
    "{\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 48.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 5800.0\n",
    "}\n",
    "```\n",
    "\n",
    "And here is an example of the output we'd like to get from the endpoint:\n",
    "\n",
    "```{json}\n",
    "{\n",
    "    \"prediction\": \"Adelie\",\n",
    "    \"confidence\": 0.802672\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b597447",
   "metadata": {},
   "source": [
    "### Step 1 - Creating the Preprocessing Script\n",
    "\n",
    "The first component of our inference pipeline will transform the input data into the format the model expects.\n",
    "\n",
    "We'll use the Scikit-Learn transformer we saved when we split and transformed the data. To deploy this component as part of an inference pipeline, we need to write a script that loads the transformer, uses it to modify the input data, and returns the output in the format the TensorFlow model expects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1de322",
   "metadata": {},
   "source": [
    "We'll store the scripts of every component in a folder called `pipeline` and add it to the system path so we can later import it as a module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f25973",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"pipeline\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1cc77f",
   "metadata": {},
   "source": [
    "Let's now create the script for the preprocessing component:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480ae02",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/pipeline/preprocessing_component.py\n",
    "#| filename: preprocessing_component.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import worker\n",
    "except ImportError:\n",
    "    # We don't have access to the `worker` package when testing locally.\n",
    "    # We'll set it to None so we can change the way functions create\n",
    "    # a response.\n",
    "    worker = None\n",
    "\n",
    "\n",
    "TARGET_COLUMN = \"species\"\n",
    "FEATURE_COLUMNS = [\n",
    "    \"island\",\n",
    "    \"culmen_length_mm\",\n",
    "    \"culmen_depth_mm\",\n",
    "    \"flipper_length_mm\",\n",
    "    \"body_mass_g\",\n",
    "    \"sex\",\n",
    "]\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserializes the model that will be used in this container.\n",
    "    \"\"\"\n",
    "\n",
    "    return joblib.load(os.path.join(model_dir, \"features.joblib\"))\n",
    "\n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "    \"\"\"\n",
    "    Parses the input payload and creates a Pandas DataFrame.\n",
    "\n",
    "    This function will check whether the target column is present in the\n",
    "    input data and will remove it.\n",
    "    \"\"\"\n",
    "\n",
    "    if content_type == \"text/csv\":\n",
    "        df = pd.read_csv(StringIO(input_data), header=None, skipinitialspace=True)\n",
    "\n",
    "        # If we find an extra column, it's probably the target\n",
    "        # feature, so let's drop it. We'll assume the target\n",
    "        # is always the first column,\n",
    "        if len(df.columns) == len(FEATURE_COLUMNS) + 1:\n",
    "            df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "        df.columns = FEATURE_COLUMNS\n",
    "        return df\n",
    "\n",
    "    if content_type == \"application/json\":\n",
    "        df = pd.DataFrame([json.loads(input_data)])\n",
    "\n",
    "        if TARGET_COLUMN in df.columns:\n",
    "            df = df.drop(TARGET_COLUMN, axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    raise ValueError(f\"{content_type} is not supported!\")\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Preprocess the input using the transformer.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return model.transform(input_data)\n",
    "    except ValueError as e:\n",
    "        print(\"Error transforming the input data\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"\n",
    "    Formats the prediction output to generate a response.\n",
    "\n",
    "    The default accept/content-type between containers for serial inference\n",
    "    is JSON. Since this model preceeds a TensorFlow model, we want to\n",
    "    return a JSON object following TensorFlow's input requirements.\n",
    "    \"\"\"\n",
    "\n",
    "    if prediction is None:\n",
    "        raise Exception(\"There was an error transforming the input data\")\n",
    "\n",
    "    instances = [p for p in prediction.tolist()]\n",
    "    response = {\"instances\": instances}\n",
    "    return (\n",
    "        worker.Response(json.dumps(response), mimetype=accept)\n",
    "        if worker\n",
    "        else (response, accept)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582ba8b",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34721e63",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "#| code-fold: true\n",
    "\n",
    "from pipeline.preprocessing_component import input_fn, predict_fn, output_fn, model_fn\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    \n",
    "    preprocess(base_directory=directory)\n",
    "    \n",
    "    with tarfile.open(directory / \"model\" / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=directory / \"model\")\n",
    "    \n",
    "    yield directory / \"model\"\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_input_csv_drops_target_column_if_present():\n",
    "    input_data = \"\"\"\n",
    "    Adelie, Torgersen, 39.1, 18.7, 181, 3750, MALE\n",
    "    \"\"\"\n",
    "    \n",
    "    df = input_fn(input_data, \"text/csv\")\n",
    "    assert len(df.columns) == 6 and \"species\" not in df.columns\n",
    "\n",
    "\n",
    "def test_input_json_drops_target_column_if_present():\n",
    "    input_data = json.dumps({\n",
    "        \"species\": \"Adelie\", \n",
    "        \"island\": \"Torgersen\",\n",
    "        \"culmen_length_mm\": 44.1,\n",
    "        \"culmen_depth_mm\": 18.0,\n",
    "        \"flipper_length_mm\": 210.0,\n",
    "        \"body_mass_g\": 4000.0,\n",
    "        \"sex\": \"MALE\"\n",
    "    })\n",
    "    \n",
    "    df = input_fn(input_data, \"application/json\")\n",
    "    assert len(df.columns) == 6 and \"species\" not in df.columns\n",
    "\n",
    "\n",
    "def test_input_csv_works_without_target_column():\n",
    "    input_data = \"\"\"\n",
    "    Torgersen, 39.1, 18.7, 181, 3750, MALE\n",
    "    \"\"\"\n",
    "    \n",
    "    df = input_fn(input_data, \"text/csv\")\n",
    "    assert len(df.columns) == 6\n",
    "\n",
    "\n",
    "def test_input_json_works_without_target_column():\n",
    "    input_data = json.dumps({\n",
    "        \"island\": \"Torgersen\",\n",
    "        \"culmen_length_mm\": 44.1,\n",
    "        \"culmen_depth_mm\": 18.0,\n",
    "        \"flipper_length_mm\": 210.0,\n",
    "        \"body_mass_g\": 4000.0,\n",
    "        \"sex\": \"MALE\"\n",
    "    })\n",
    "    \n",
    "    df = input_fn(input_data, \"application/json\")\n",
    "    assert len(df.columns) == 6\n",
    "\n",
    "\n",
    "def test_output_raises_exception_if_prediction_is_none():\n",
    "    with pytest.raises(Exception):\n",
    "        output_fn(None, \"application/json\")\n",
    "    \n",
    "    \n",
    "def test_output_returns_tensorflow_ready_input():\n",
    "    prediction = np.array([\n",
    "        [-1.3944109908736013,1.15488062669371,-0.7954340636549508,-0.5536447804097907,0.0,1.0,0.0],\n",
    "        [1.0557485835338234,0.5040085971987002,-0.5824506029515057,-0.5851840035995248,0.0,1.0,0.0]\n",
    "    ])\n",
    "    \n",
    "    response = output_fn(prediction, \"application/json\")\n",
    "    \n",
    "    assert response[0] == {\n",
    "        \"instances\": [\n",
    "            [-1.3944109908736013,1.15488062669371,-0.7954340636549508,-0.5536447804097907,0.0,1.0,0.0],\n",
    "            [1.0557485835338234,0.5040085971987002,-0.5824506029515057,-0.5851840035995248,0.0,1.0,0.0]\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    assert response[1] == \"application/json\"\n",
    "\n",
    "    \n",
    "def test_predict_transforms_data(directory):\n",
    "    input_data = \"\"\"\n",
    "    Torgersen, 39.1, 18.7, 181, 3750, MALE\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model_fn(directory.as_posix())\n",
    "    df = input_fn(input_data, \"text/csv\")\n",
    "    response = predict_fn(df, model)\n",
    "    assert type(response) is np.ndarray\n",
    "    \n",
    "\n",
    "def test_predict_returns_none_if_invalid_input(directory):\n",
    "    input_data = \"\"\"\n",
    "    Invalid, 39.1, 18.7, 181, 3750, MALE\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model_fn(directory.as_posix())\n",
    "    df = input_fn(input_data, \"text/csv\")\n",
    "    assert predict_fn(df, model) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12017c",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Postprocessing Script\n",
    "\n",
    "The final component of our inference pipeline will transform the output from the model into a human-readable format.\n",
    "\n",
    "We'll use the Scikit-Learn target transformer we saved when we split and transformed the data. To deploy this component as part of an inference pipeline, we need to write a script that loads the transformer, uses it to modify the output from the model, and returns a human-readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23798aa",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/pipeline/postprocessing_component.py\n",
    "#| filename: postprocessing_component.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import encoders, worker\n",
    "except ImportError:\n",
    "    # We don't have access to the `worker` package when testing locally.\n",
    "    # We'll set it to None so we can change the way functions create\n",
    "    # a response.\n",
    "    worker = None\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserializes the target model and returns the list of fitted categories.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(os.path.join(model_dir, \"target.joblib\"))\n",
    "    return model.named_transformers_[\"species\"].categories_[0]\n",
    "\n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "    if content_type == \"application/json\":\n",
    "        return json.loads(input_data)[\"predictions\"]\n",
    "    \n",
    "    raise ValueError(f\"{content_type} is not supported.\")\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Transforms the prediction into its corresponding category.\n",
    "    \"\"\"\n",
    "    predictions = np.argmax(input_data, axis=-1)\n",
    "    confidence = np.max(input_data, axis=-1)\n",
    "    return [\n",
    "        (model[prediction], confidence)\n",
    "        for confidence, prediction in zip(confidence, predictions)\n",
    "    ]\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    if accept == \"text/csv\":\n",
    "        return (\n",
    "            worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "            if worker\n",
    "            else (prediction, accept)\n",
    "        )\n",
    "\n",
    "    if accept == \"application/json\":\n",
    "        response = []\n",
    "        for p, c in prediction:\n",
    "            response.append({\"prediction\": p, \"confidence\": c})\n",
    "\n",
    "        # If there's only one prediction, we'll return it\n",
    "        # as a single object.\n",
    "        if len(response) == 1:\n",
    "            response = response[0]\n",
    "\n",
    "        return (\n",
    "            worker.Response(json.dumps(response), mimetype=accept)\n",
    "            if worker\n",
    "            else (response, accept)\n",
    "        )\n",
    "\n",
    "    raise Exception(f\"{accept} accept type is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67725bb1",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a6be5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "#| code-fold: true\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pipeline.postprocessing_component import predict_fn, output_fn\n",
    "\n",
    "\n",
    "def test_predict_returns_prediction_as_first_column():\n",
    "    input_data = [\n",
    "        [0.6, 0.2, 0.2], \n",
    "        [0.1, 0.8, 0.1],\n",
    "        [0.2, 0.1, 0.7]\n",
    "    ]\n",
    "    \n",
    "    categories = [\"Adelie\", \"Gentoo\", \"Chinstrap\"]\n",
    "    \n",
    "    response = predict_fn(input_data, categories)\n",
    "    \n",
    "    assert response == [\n",
    "        (\"Adelie\", 0.6),\n",
    "        (\"Gentoo\", 0.8),\n",
    "        (\"Chinstrap\", 0.7)\n",
    "    ]\n",
    "\n",
    "\n",
    "def test_output_does_not_return_array_if_single_prediction():\n",
    "    prediction = [(\"Adelie\", 0.6)]\n",
    "    response, _ = output_fn(prediction, \"application/json\")\n",
    "\n",
    "    assert response[\"prediction\"] == \"Adelie\"\n",
    "\n",
    "\n",
    "def test_output_returns_array_if_multiple_predictions():\n",
    "    prediction = [(\"Adelie\", 0.6), (\"Gentoo\", 0.8)]\n",
    "    response, _ = output_fn(prediction, \"application/json\")\n",
    "\n",
    "    assert len(response) == 2\n",
    "    assert response[0][\"prediction\"] == \"Adelie\"\n",
    "    assert response[1][\"prediction\"] == \"Gentoo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29abbf51",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up the Inference Pipeline\n",
    "\n",
    "We can now create a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/api/inference/pipeline.html#sagemaker.pipeline.PipelineModel) to define our inference pipeline.\n",
    "\n",
    "We'll use the model we generated in the Split and Transform step as the input to the first and last components of the inference pipeline. This `model.tar.gz` file contains the two transformers we need to preprocess and postprocess the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf32c18",
   "metadata": {},
   "source": [
    "Let's create a variable with the URI to this file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dafcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_pipeline_model = Join(\n",
    "    on=\"/\",\n",
    "    values=[\n",
    "        preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"model\"\n",
    "        ].S3Output.S3Uri,\n",
    "        \"model.tar.gz\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab6b5b",
   "metadata": {},
   "source": [
    "Here is the first component of the inference pipeline. It will preprocess the data before sending it to the TensorFlow model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7dda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "preprocessing_model = SKLearnModel(\n",
    "    model_data=transformation_pipeline_model,\n",
    "    entry_point=\"preprocessing_component.py\",\n",
    "    source_dir=(CODE_FOLDER / \"pipeline\").as_posix(),\n",
    "    framework_version=\"1.2-1\",\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71a20b",
   "metadata": {},
   "source": [
    "Here is the last component of the inference pipeline. It will postprocess the output from the TensorFlow model before sending it back to the user:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing_model = SKLearnModel(\n",
    "    model_data=transformation_pipeline_model,\n",
    "    entry_point=\"postprocessing_component.py\",\n",
    "    source_dir=(CODE_FOLDER / \"pipeline\").as_posix(),\n",
    "    framework_version=\"1.2-1\",\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba11abe",
   "metadata": {},
   "source": [
    "We can now create the inference pipeline using the three models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa95ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"inference-model\",\n",
    "    models=[preprocessing_model, tensorflow_model, postprocessing_model],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d7393",
   "metadata": {},
   "source": [
    "### Step 4 - Configuring the Model Package Group\n",
    "\n",
    "Let's define a new package group to register the Pipeline Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c052332",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_MODEL_PACKAGE_GROUP = \"pipeline-penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7b2df",
   "metadata": {},
   "source": [
    "### Step 5 - Registering the Model\n",
    "\n",
    "We'll modify the registration step to register the Pipeline Model in the Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0ce9e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "register_model_step = create_registration_step(\n",
    "    pipeline_model,\n",
    "    PIPELINE_MODEL_PACKAGE_GROUP,\n",
    "    content_types=[\"text/csv\", \"application/json\"],\n",
    "    response_types=[\"text/csv\", \"application/json\"],\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55883c31",
   "metadata": {},
   "source": [
    "### Step 6 - Modifying the Deploy Step\n",
    "\n",
    "Let's now modify the [LambdaStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) to use the updated Registration Step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_step = create_deployment_step(register_model_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a4ebb-fb21-4935-9d7b-9500e47e07f9",
   "metadata": {},
   "source": [
    "### Step 7 - Modifying the Condition Step\n",
    "\n",
    "Since we modified the Registration Step, we also need to modify the Condition Step to use the new registration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9712905-9fe3-4148-ae6d-05b0a48e742e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step, deploy_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730a388",
   "metadata": {},
   "source": [
    "### Step 8 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9f51d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session14_pipeline = Pipeline(\n",
    "    name=\"session14-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session14_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe7356-53e8-4ac1-9a7f-3bd51bb739a5",
   "metadata": {},
   "source": [
    "### Step 9 - Testing the Endpoint\n",
    "\n",
    "Let's now test the endpoint. Notice that we can now send the raw data to the endpoint, and it will return the penguin's species in a human-readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc966fb-b611-417f-a8b8-0c5d2f95252c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=ENDPOINT,\n",
    "    serializer=CSVSerializer(),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "data = pd.read_csv(DATA_FILEPATH)\n",
    "data = data.drop(\"species\", axis=1)\n",
    "\n",
    "payload = data.iloc[:3].to_csv(header=False, index=False)\n",
    "print(f\"Payload:\\n{payload}\")\n",
    "\n",
    "try:\n",
    "    wait_for_endpoint()\n",
    "\n",
    "    response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    response = json.loads(response.decode(\"utf-8\"))\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd85c2",
   "metadata": {},
   "source": [
    "We can also test the endpoint by sending a JSON payload. Notice how you can use a deserealizer to automatically decode the response from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "sample = {\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 48.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 5800.0,\n",
    "    \"sex\": \"MALE\",\n",
    "}\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=ENDPOINT,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = predictor.predict(sample)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697dce40",
   "metadata": {},
   "source": [
    "And now let's send the same payload but return the prediction in CSV format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240aaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=ENDPOINT,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=CSVDeserializer(),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = predictor.predict(sample, initial_args={\"Accept\": \"text/csv\"})\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3b50c",
   "metadata": {},
   "source": [
    "## Session 15 - Custom Inference Script\n",
    "\n",
    "This session creates a custom inference script to control the inference process in the SageMaker endpoint. This is an alternative to creating an inference pipeline to preprocess and postprocess the data that comes in and out of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527690f",
   "metadata": {},
   "source": [
    "### Step 1 - Creating the Inference Script\n",
    "\n",
    "Let's create a script where we'll manage the inference process in the endpoint.\n",
    "\n",
    "We'll' include this code as part of the model assets to control the inference process on the SageMaker endpoint. SageMaker will automatically call the `handler()` function for every request to the endpoint. Check [How to implement the pre- and/or post-processing handler(s)](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html#how-to-implement-the-pre-and-or-post-processing-handler-s) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b90af",
   "metadata": {},
   "source": [
    "We can now create the script inside the folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b3cd80",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/pipeline/inference.py\n",
    "#| filename: inference.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def handler(data, context, directory=Path(\"/opt/ml/model\")):\n",
    "    \"\"\"\n",
    "    This is the entrypoint that will be called by SageMaker\n",
    "    when the endpoint receives a request.\n",
    "    \"\"\"\n",
    "    print(\"Handling endpoint request\")\n",
    "\n",
    "    processed_input = _process_input(data, context, directory)\n",
    "    output = _predict(processed_input, context, directory) if processed_input else None\n",
    "    return _process_output(output, context, directory)\n",
    "\n",
    "\n",
    "def _process_input(data, context, directory):\n",
    "    print(\"Processing input data...\")\n",
    "\n",
    "    if context is None:\n",
    "        # The context will be None when we are testing the code\n",
    "        # directly from a notebook. In that case, we can use the\n",
    "        # data directly.\n",
    "        endpoint_input = data\n",
    "    elif context.request_content_type in (\n",
    "        \"application/json\",\n",
    "        \"application/octet-stream\",\n",
    "    ):\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. We need to parse the input and turn it into\n",
    "        # JSON in that case.\n",
    "        endpoint_input = data.read().decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unsupported content type: {context.request_content_type or 'unknown'}\"\n",
    "        )\n",
    "\n",
    "    # Let's now transform the input data using the features pipeline.\n",
    "    try:\n",
    "        endpoint_input = json.loads(endpoint_input)\n",
    "        df = pd.json_normalize(endpoint_input)\n",
    "        features_pipeline = joblib.load(directory / \"features.joblib\")\n",
    "        result = features_pipeline.transform(df)\n",
    "    except Exception as e:\n",
    "        print(f\"There was an error processing the input data. {e}\")\n",
    "        return None\n",
    "\n",
    "    return result[0].tolist()\n",
    "\n",
    "\n",
    "def _predict(instance, context, directory):\n",
    "    print(\"Sending input data to model to make a prediction...\")\n",
    "\n",
    "    if context is None:\n",
    "        # The context will be None when we are testing the code\n",
    "        # directly from a notebook. In that case, we want to load the\n",
    "        # model we trained and make a prediction using it.\n",
    "        import keras\n",
    "\n",
    "        model = keras.models.load_model(Path(directory) / \"001\")\n",
    "        predictions = model.predict(np.array([instance]))\n",
    "        result = {\"predictions\": predictions.tolist()}\n",
    "    else:\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. In that case we need to send the instance to the\n",
    "        # model to get a prediction back.\n",
    "        model_input = json.dumps({\"instances\": [instance]})\n",
    "        response = requests.post(context.rest_uri, data=model_input)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(response.content.decode(\"utf-8\"))\n",
    "\n",
    "        result = json.loads(response.content)\n",
    "\n",
    "    print(f\"Response: {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def _process_output(output, context, directory):\n",
    "    print(\"Processing prediction received from the model...\")\n",
    "\n",
    "    if output:\n",
    "        prediction = np.argmax(output[\"predictions\"][0])\n",
    "        confidence = output[\"predictions\"][0][prediction]\n",
    "\n",
    "        target_pipeline = joblib.load(directory / \"target.joblib\")\n",
    "        classes = target_pipeline.named_transformers_[\"species\"].categories_[0]\n",
    "\n",
    "        result = {\n",
    "            \"prediction\": classes[prediction],\n",
    "            \"confidence\": confidence,\n",
    "        }\n",
    "    else:\n",
    "        result = {\"prediction\": None}\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    response_content_type = (\n",
    "        \"application/json\" if context is None else context.accept_header\n",
    "    )\n",
    "    return json.dumps(result), response_content_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbf40d",
   "metadata": {},
   "source": [
    "Let's test the script to ensure everything is working as expected:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91786cc7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "\n",
    "from processing.script import preprocess\n",
    "from training.script import train\n",
    "from pipeline.inference import handler\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "\n",
    "    directory = Path(directory)\n",
    "\n",
    "    preprocess(base_directory=directory)\n",
    "\n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\",\n",
    "        validation_path=directory / \"validation\",\n",
    "        pipeline_path=directory / \"model\",\n",
    "        experiment=None,\n",
    "        epochs=1,\n",
    "    )\n",
    "\n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model\" / \"001\", arcname=\"001\")\n",
    "\n",
    "    yield directory\n",
    "\n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def payload():\n",
    "    return json.dumps({\n",
    "        \"island\": \"Biscoe\",\n",
    "        \"culmen_length_mm\": 48.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 230.0,\n",
    "        \"body_mass_g\": 5800,\n",
    "    }).encode(\"utf-8\")\n",
    "\n",
    "\n",
    "def test_handler_response_contains_prediction_and_confidence(directory, payload):\n",
    "    response = handler(\n",
    "        data=payload,\n",
    "        context=None,\n",
    "        directory=directory / \"model\",\n",
    "    )\n",
    "\n",
    "    response = json.loads(response[0])\n",
    "    assert \"prediction\" in response\n",
    "    assert \"confidence\" in response\n",
    "\n",
    "\n",
    "def test_handler_response_includes_content_type(directory, payload):\n",
    "    response = handler(\n",
    "        data=payload,\n",
    "        context=None,\n",
    "        directory=directory / \"model\",\n",
    "    )\n",
    "\n",
    "    assert response[1] == \"application/json\"\n",
    "\n",
    "\n",
    "def test_handler_response_prediction_is_categorical(directory, payload):\n",
    "    response = handler(\n",
    "        data=payload,\n",
    "        context=None,\n",
    "        directory=directory / \"model\",\n",
    "    )\n",
    "\n",
    "    response = json.loads(response[0])\n",
    "    assert response[\"prediction\"] in [\"Adelie\", \"Gentoo\", \"Chinstrap\"]\n",
    "\n",
    "\n",
    "def test_handler_deals_with_an_invalid_payload(directory):\n",
    "    response = handler(\n",
    "        data=\"invalid payload\",\n",
    "        context=None,\n",
    "        directory=directory / \"model\",\n",
    "    )\n",
    "\n",
    "    response = json.loads(response[0])\n",
    "    assert response[\"prediction\"] is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57430168",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Model\n",
    "\n",
    "We can now create a new [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-model) including the `inference.py` file.\n",
    "\n",
    "SageMaker triggers a repack operation whenever we specify the `source_dir` attribute in a model. We want that attribute to point to the local folder containing the `inference.py` file. SageMaker will automatically modify the original `model.tar.gz` package to include a `/code` folder containing the file.\n",
    "\n",
    "Since we need access to Scikit-Learn in our script, we can include a `requirements.txt` file in the same location where the `inference.py` script is, and SageMaker will install everything in it.\n",
    "\n",
    "To repack the model assets, SageMaker will automatically include a new step in the pipeline right before registering the model.\n",
    "\n",
    "Here is what the new `model.tar.gz` package will look like:\n",
    "\n",
    "```\n",
    "model/\n",
    "    |--[model_version_number]\n",
    "        |--assets/\n",
    "        |--variables/\n",
    "        |--saved_model.pb\n",
    "    |--features.joblib\n",
    "    |--target.joblib\n",
    "code/\n",
    "    |--inference.py\n",
    "    |--requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3cfdd3",
   "metadata": {},
   "source": [
    "Let's create a `requirements.txt` file with all the libraries we want SageMaker to install in the inference container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cb8f5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/pipeline/requirements.txt\n",
    "#| filename: requirements.txt\n",
    "#| code-line-numbers: true\n",
    "\n",
    "numpy\n",
    "pandas\n",
    "scikit-learn==1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c7a0d",
   "metadata": {},
   "source": [
    "We can now create the model using the `inference.py` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5015c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tensorflow_model = TensorFlowModel(\n",
    "    name=\"penguins\",\n",
    "    model_data=train_model_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=(CODE_FOLDER / \"pipeline\").as_posix(),\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce15c7",
   "metadata": {},
   "source": [
    "### Step 3 - Configuring the Model Package Group\n",
    "\n",
    "Let's define a new group where we'll register the model using the custom `inference.py` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_PACKAGE_GROUP = \"custom-penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b5c0a",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "We can now modify the registration step to register the custom model in the Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb3e2c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "register_model_step = create_registration_step(\n",
    "    custom_tensorflow_model,\n",
    "    model_package_group_name=CUSTOM_MODEL_PACKAGE_GROUP,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9293b0",
   "metadata": {},
   "source": [
    "### Step 5 - Modifying the Deploy Step\n",
    "\n",
    "Let's now modify the [LambdaStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) to use the updated Registration Step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8162b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_step = create_deployment_step(register_model_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1812e7",
   "metadata": {},
   "source": [
    "### Step 6 - Modifying the Condition Step\n",
    "\n",
    "Since we modified the Registration Step, we also need to modify the Condition Step to use the new registration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step, deploy_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a5efb",
   "metadata": {},
   "source": [
    "### Step 7 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64921ee",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session15_pipeline = Pipeline(\n",
    "    name=\"session15-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session15_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f02a4",
   "metadata": {},
   "source": [
    "### Step 8 - Testing the Endpoint\n",
    "\n",
    "Let's test the endpoint to make sure it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "try:\n",
    "    wait_for_endpoint()\n",
    "\n",
    "    predictor = Predictor(\n",
    "        endpoint_name=ENDPOINT,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer(),\n",
    "    )\n",
    "\n",
    "    response = predictor.predict(\n",
    "        {\n",
    "            \"island\": \"Dream\",\n",
    "            \"culmen_length_mm\": 46.4,\n",
    "            \"culmen_depth_mm\": 18.6,\n",
    "            \"flipper_length_mm\": 190.0,\n",
    "            \"body_mass_g\": 3450.0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c7a3a1",
   "metadata": {},
   "source": [
    "## Session 16 - Data Quality Baseline\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compute a baseline for the data the endpoint expects.\n",
    "\n",
    "This step will compute statistics and constraints from the data. We'll' later use this information as the baseline to detect data drift and other data quality issues.\n",
    "\n",
    "<a href=\"images/data-quality-baseline.png\" target=\"_blank\"> <img src=\"images/data-quality-baseline.png\" alt=\"Data Quality Baseline\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Check [Monitor data quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html) for more information about monitoring data quality in SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb16c8",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Baseline Location\n",
    "\n",
    "Let's start by defining the location where SageMaker will store the baseline data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4747fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/data-quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae1030",
   "metadata": {},
   "source": [
    "### Step 2 - Generating Data Quality Baseline\n",
    "\n",
    "Let's configure a [QualityCheck Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compute the general statistics of the data we used to build our model.\n",
    "\n",
    "We can configure the instance that will run the quality check using the [CheckJobConfig](https://sagemaker.readthedocs.io/en/v2.73.0/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.check_job_config.CheckJobConfig) class, and we can use the `DataQualityCheckConfig` class to configure the job.\n",
    "\n",
    "We are running this step with the following configuration:\n",
    "\n",
    "-   `skip_check = True`: This parameter controls whether the step should skip checking the data against a previous baseline. Since we want to generate the baseline for the first time, we set it to `True`. After running the pipeline once to generate the baseline, we can set this parameter to `False` to ensure any new data follows the same distribution as the baseline.\n",
    "\n",
    "-   `register_new_baseline = True`: This parameter controls whether the new calculated baseline will be registered in the Model Registry.\n",
    "\n",
    "For more information about these configuration parameters, check [Baseline calculation and registration](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc728fa",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.quality_check_step import (\n",
    "    DataQualityCheckConfig,\n",
    "    QualityCheckStep,\n",
    ")\n",
    "\n",
    "data_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-data-quality-baseline\",\n",
    "    check_job_config=CheckJobConfig(\n",
    "        instance_type=\"ml.c5.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "        role=role,\n",
    "    ),\n",
    "    quality_check_config=DataQualityCheckConfig(\n",
    "        baseline_dataset=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"train-baseline\"\n",
    "        ].S3Output.S3Uri,\n",
    "        dataset_format=DatasetFormat.csv(header=True),\n",
    "        output_s3_uri=DATA_QUALITY_LOCATION,\n",
    "    ),\n",
    "    model_package_group_name=PIPELINE_MODEL_PACKAGE_GROUP,\n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac2646",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up Model Metrics\n",
    "\n",
    "We can configure a new set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) using the results of the Quality Step. Check [Baseline and model version lifecycle and evolution with SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html#pipelines-quality-clarify-baseline-evolution) for an explanation of how SageMaker uses the `DriftCheckBaselines`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "data_quality_model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "data_quality_drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce8965",
   "metadata": {},
   "source": [
    "### Step 4 - Registering the Model\n",
    "\n",
    "Let's modify the registration step to use the new metrics and the drift baseline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c4325",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "register_model_step = create_registration_step(\n",
    "    pipeline_model,\n",
    "    PIPELINE_MODEL_PACKAGE_GROUP,\n",
    "    content_types=[\"text/csv\", \"application/json\"],\n",
    "    response_types=[\"text/csv\", \"application/json\"],\n",
    "    model_metrics=data_quality_model_metrics,\n",
    "    drift_check_baselines=data_quality_drift_check_baselines,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81802ef",
   "metadata": {},
   "source": [
    "### Step 5 - Modifying the Condition Step\n",
    "\n",
    "Since we modified the Registration Step, we also need to modify the Condition Step to use the new registration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea28519",
   "metadata": {},
   "source": [
    "### Step 6 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b8d1e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session16_pipeline = Pipeline(\n",
    "    name=\"session16-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "        evaluate_model_step,\n",
    "        data_quality_baseline_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session16_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88501998",
   "metadata": {},
   "source": [
    "### Step 7 - Checking Constraints and Statistics\n",
    "\n",
    "Our pipeline generated data baseline statistics and constraints. We can take a look at what these values look like by downloading them from S3. You need to wait for the pipeline to finish running before these files are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4a917",
   "metadata": {},
   "source": [
    "Here are the data quality statistics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b95d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = json.loads(\n",
    "        S3Downloader.read_file(f\"{DATA_QUALITY_LOCATION}/statistics.json\"),\n",
    "    )\n",
    "    print(json.dumps(response[\"features\"][0], indent=2))\n",
    "except Exception:  # noqa: S110\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436b273",
   "metadata": {},
   "source": [
    "Here are the data quality constraints:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63908598",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = json.loads(\n",
    "        S3Downloader.read_file(f\"{DATA_QUALITY_LOCATION}/constraints.json\"),\n",
    "    )\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception:  # noqa: S110\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631cf7b",
   "metadata": {},
   "source": [
    "## Session 17 - Model Quality Baseline\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a [QualityCheck Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compute a baseline for the model performance.\n",
    "\n",
    "This step will compute the baseline metrics we will later use as the baseline to detect model drift.\n",
    "\n",
    "To create a baseline to compare the model performance, we must create predictions for the test set and compare the model's metrics with the model performance on production data. We can do this by running a [Batch Transform Job](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to predict every sample from the test set. We can use a [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) as part of the pipeline to run this job.\n",
    "\n",
    "<a href=\"images/model-quality-baseline.png\" target=\"_blank\"> <img src=\"images/model-quality-baseline.png\" alt=\"Model Quality Baseline\" style=\"max-width: 740px;\" /></a>\n",
    "\n",
    "Check [Monitor model quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html) for more information about monitoring model quality in SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df4f23",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Baseline Location\n",
    "\n",
    "Let's start by defining the location where SageMaker will store the baseline data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e115c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/model-quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a633b",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Model\n",
    "\n",
    "The [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) requires a model to generate predictions, so we need a [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) that creates a model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f2751",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "create_model_step = ModelStep(\n",
    "    name=\"create-model\",\n",
    "    step_args=pipeline_model.create(instance_type=config[\"instance_type\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac142cc0",
   "metadata": {},
   "source": [
    "### Step 3 - Setting up the Transform Step\n",
    "\n",
    "We are going to use a [Batch Transform Job](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to generate predictions for every sample from the test set.\n",
    "\n",
    "This Batch Transform Job will run every sample from the training dataset through the model so we can compute the baseline metrics. Check [Run a Batch Transform Job](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#run-a-batch-transform-job) for more information about running a Batch Transform Job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227e304",
   "metadata": {},
   "source": [
    "Let's start by configuring a [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a530d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    strategy=\"MultiRecord\",\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f\"{S3_LOCATION}/transform\",\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfde28",
   "metadata": {},
   "source": [
    "We can now set up the [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) using the [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) we configured before.\n",
    "\n",
    "Notice the following:\n",
    "\n",
    "-   We'll generate predictions for the baseline test data that we generated when we split and transformed the data. This baseline is the same data we used to test the model, but it's in raw format.\n",
    "-   The output of this Batch Transform Job will have two fields. The first one will be the ground truth label, and the second one will be the prediction of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c6ec8",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "generate_test_predictions_step = TransformStep(\n",
    "    name=\"generate-test-predictions\",\n",
    "    step_args=transformer.transform(\n",
    "        # We will use the baseline set we generated when we split the data.\n",
    "        # This set corresponds to the test split before the transformation step.\n",
    "        data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"test-baseline\"\n",
    "        ].S3Output.S3Uri,\n",
    "        join_source=\"Input\",\n",
    "        split_type=\"Line\",\n",
    "        content_type=\"text/csv\",\n",
    "        # We want to output the first and the second to last field from\n",
    "        # the joint set. The first field corresponds to the groundtruth,\n",
    "        # and the second to last field corresponds to the prediction.\n",
    "        #\n",
    "        # Here is an example of the data the Transform Job will generate\n",
    "        # after joining the input with the output from the model:\n",
    "        #\n",
    "        # Gentoo,39.1,18.7,181.0,3750.0,MALE,Gentoo,0.52\n",
    "        #\n",
    "        # Notice how the first field is the groundtruth coming from the\n",
    "        # test set. The second to last field is the prediction coming the\n",
    "        # model.\n",
    "        output_filter=\"$[0,-2]\",\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956e12b",
   "metadata": {},
   "source": [
    "### Step 4 - Generating Model Quality Baseline\n",
    "\n",
    "Let's now configure the [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and feed it the data we generated in the Transform Step. This step will automatically compute the performance metrics of the model on the test set.\n",
    "\n",
    "We are running this step with the following configuration:\n",
    "\n",
    "-   `skip_check = True`: This parameter controls whether the step should skip checking the data against a previous baseline. Since we want to generate the baseline for the first time, we set it to `True`. After running the pipeline once to generate the baseline, we can set this parameter to `False` to ensure any new data follows the same distribution as the baseline.\n",
    "\n",
    "-   `register_new_baseline = True`: This parameter controls whether the new calculated baseline will be registered in the Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a9ed5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.quality_check_step import ModelQualityCheckConfig\n",
    "\n",
    "model_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-model-quality-baseline\",\n",
    "    check_job_config=CheckJobConfig(\n",
    "        instance_type=\"ml.c5.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "        role=role,\n",
    "    ),\n",
    "    quality_check_config=ModelQualityCheckConfig(\n",
    "        # We are going to use the output of the Transform Step to generate\n",
    "        # the model quality baseline.\n",
    "        baseline_dataset=generate_test_predictions_step.properties.TransformOutput.S3OutputPath,\n",
    "        dataset_format=DatasetFormat.csv(header=False),\n",
    "        # We need to specify the problem type and the fields where the prediction\n",
    "        # and groundtruth are so the process knows how to interpret the results.\n",
    "        problem_type=\"MulticlassClassification\",\n",
    "        # Since the data doesn't have headers, SageMaker will autocreate headers for it.\n",
    "        # _c0 corresponds to the first column, and _c1 corresponds to the second column.\n",
    "        ground_truth_attribute=\"_c0\",\n",
    "        inference_attribute=\"_c1\",\n",
    "        output_s3_uri=MODEL_QUALITY_LOCATION,\n",
    "    ),\n",
    "    model_package_group_name=PIPELINE_MODEL_PACKAGE_GROUP,\n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1f847",
   "metadata": {},
   "source": [
    "### Step 5 - Setting up Model Metrics\n",
    "\n",
    "We can configure a new set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) using the results of the Quality Step. Check [Baseline and model version lifecycle and evolution with SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html#pipelines-quality-clarify-baseline-evolution) for an explanation of how SageMaker uses the `DriftCheckBaselines`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "model_quality_model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "model_quality_drift_check_baselines = DriftCheckBaselines(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ca87f",
   "metadata": {},
   "source": [
    "### Step 6 - Registering the Model\n",
    "\n",
    "Let's modify the registration step to use the new metrics and the drift baseline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20154a1a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "register_model_step = create_registration_step(\n",
    "    pipeline_model,\n",
    "    PIPELINE_MODEL_PACKAGE_GROUP,\n",
    "    content_types=[\"text/csv\", \"application/json\"],\n",
    "    response_types=[\"text/csv\", \"application/json\"],\n",
    "    model_metrics=model_quality_model_metrics,\n",
    "    drift_check_baselines=model_quality_drift_check_baselines,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725d23c",
   "metadata": {},
   "source": [
    "### Step 7 - Modifying the Condition Step\n",
    "\n",
    "We need to modify the Condition Step to include the new Registration Step and the Transform and Quality Check Steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition],\n",
    "    if_steps=(\n",
    "        [\n",
    "            create_model_step,\n",
    "            generate_test_predictions_step,\n",
    "            model_quality_baseline_step,\n",
    "            register_model_step,\n",
    "        ]\n",
    "    ),\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d9f1f",
   "metadata": {},
   "source": [
    "### Step 8 - Creating the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244e206",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "session17_pipeline = Pipeline(\n",
    "    name=\"session17-pipeline\",\n",
    "    parameters=[dataset_location, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "        evaluate_model_step,\n",
    "        data_quality_baseline_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session17_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fdc363",
   "metadata": {},
   "source": [
    "### Step 9 - Checking Constraints\n",
    "\n",
    "Our pipeline generated model baseline constraints. We can take a look at what these values look like by downloading them from S3. You need to wait for the pipeline to finish running before the file is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = json.loads(\n",
    "        S3Downloader.read_file(f\"{MODEL_QUALITY_LOCATION}/constraints.json\"),\n",
    "    )\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception:  # noqa: S110\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9b8b7",
   "metadata": {},
   "source": [
    "## Session 18 - Data Monitoring\n",
    "\n",
    "This session creates a Monitoring Job to monitor the quality of the data received by the endpoint. This schedule will run periodically and check the data that goes into the endpoint against the baseline we generated before.\n",
    "\n",
    "Check [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html) for an explanation of how to use SageMaker's Model Monitoring functionality. [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) is a much more extensive guide to monitoring in Amazon SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732149d",
   "metadata": {},
   "source": [
    "### Step 1 - Deploying the Model\n",
    "\n",
    "Let's deploy the latest approved model to an endpoint.\n",
    "\n",
    "Since we need to do the same later, we can create a function to deploy the model. Notice how we need to enable Data Capture to monitor the data that goes in and out of the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "\n",
    "def deploy_model():\n",
    "    \"\"\"Deploy the latest model registered in the Model Registry.\"\"\"\n",
    "    response = sagemaker_client.list_model_packages(\n",
    "        ModelPackageGroupName=PIPELINE_MODEL_PACKAGE_GROUP,\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        MaxResults=1,\n",
    "    )\n",
    "\n",
    "    package = (\n",
    "        response[\"ModelPackageSummaryList\"][0]\n",
    "        if response[\"ModelPackageSummaryList\"]\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    if package:\n",
    "        model_package = ModelPackage(\n",
    "            model_package_arn=package[\"ModelPackageArn\"],\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            role=role,\n",
    "        )\n",
    "\n",
    "        model_package.deploy(\n",
    "            endpoint_name=ENDPOINT,\n",
    "            initial_instance_count=1,\n",
    "            instance_type=config[\"instance_type\"],\n",
    "            # We must enable Data Capture to monitor the model.\n",
    "            data_capture_config=DataCaptureConfig(\n",
    "                enable_capture=True,\n",
    "                sampling_percentage=100,\n",
    "                destination_s3_uri=DATA_CAPTURE_DESTINATION,\n",
    "                capture_options=[\"REQUEST\", \"RESPONSE\"],\n",
    "                csv_content_types=[\"text/csv\"],\n",
    "                json_content_types=[\"application/json\"],\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21872e7d",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966c9c2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#| eval: false\n",
    "\n",
    "deploy_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c73dd",
   "metadata": {},
   "source": [
    "### Step 2 - Generating Fake Traffic\n",
    "\n",
    "To test the monitoring functionality, we need to generate traffic to the endpoint. To generate traffic, we will send every sample from the dataset to the endpoint to simulate real prediction requests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea757af",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "\n",
    "def generate_fake_traffic():\n",
    "    \"\"\"Generate fake traffic to the endpoint.\"\"\"\n",
    "    try:\n",
    "        for index, row in data.iterrows():\n",
    "            payload = \",\".join([str(x) for x in row.to_list()])\n",
    "            predictor.predict(\n",
    "                payload,\n",
    "                initial_args={\"ContentType\": \"text/csv\", \"Accept\": \"text/csv\"},\n",
    "                # The `inference_id` field is important to match\n",
    "                # it later with a corresponding ground-truth label.\n",
    "                inference_id=str(index),\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "generate_fake_traffic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c4408",
   "metadata": {},
   "source": [
    "We can check the location where the endpoint stores the captured data, download a file, and display its content. It may take a few minutes for the first few files to show up in S3.\n",
    "\n",
    "These files contain the data captured by the endpoint in a SageMaker-specific JSON-line format. Each inference request is captured in a single line in the `jsonl` file. The line contains both the input and output merged together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = S3Downloader.list(DATA_CAPTURE_DESTINATION)\n",
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[-1])\n",
    "    print(f\"File: {files[-1]}\")\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9c62b",
   "metadata": {},
   "source": [
    "### Step 3 - Creating Custom Preprocessing Script\n",
    "\n",
    "SageMaker looks for violations in the data captured by the endpoint. By default, it combines the input data with the endpoint output and compares the result with the baseline we generated before. If we let SageMaker do this, we will get a few violations, for example an \"extra column check\" violation because the field `confidence` doesn't exist in the baseline data.\n",
    "\n",
    "We can fix these violations by creating a preprocessing script configuring the data we want the monitoring job to use. Check [Preprocessing and Postprocessing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html) for more information about how to configure these scripts.\n",
    "\n",
    "We'll store the script in a folder called `monitoring`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_QUALITY_PREPROCESSOR = \"data_quality_preprocessor.py\"\n",
    "\n",
    "(CODE_FOLDER / \"monitoring\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ddea2",
   "metadata": {},
   "source": [
    "We can now define the preprocessing script. Notice that this script will return a JSON object with a name for each feature and their value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114a817",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile {CODE_FOLDER}/monitoring/{DATA_QUALITY_PREPROCESSOR}\n",
    "# | filename: data_quality_preprocessor.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def preprocess_handler(inference_record, logger):\n",
    "    input_data = inference_record.endpoint_input.data\n",
    "    return {str(i).zfill(2): d for i, d in enumerate(input_data.split(\",\"))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1b8df",
   "metadata": {},
   "source": [
    "### Step 4 - Uploading Preprocessing Script\n",
    "\n",
    "The monitoring schedule expects an S3 location pointing to the preprocessing script. Let's upload the script to the default bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21240214",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "bucket = boto3.Session().resource(\"s3\").Bucket(config[\"session\"].default_bucket())\n",
    "prefix = Path(\"penguins/monitoring\")\n",
    "bucket.Object((prefix / DATA_QUALITY_PREPROCESSOR).as_posix()).upload_file(\n",
    "    (CODE_FOLDER / \"monitoring\" / DATA_QUALITY_PREPROCESSOR).as_posix(),\n",
    ")\n",
    "data_quality_preprocessor = f\"s3://{(bucket.name / prefix / DATA_QUALITY_PREPROCESSOR)}\"\n",
    "data_quality_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd191e",
   "metadata": {},
   "source": [
    "### Step 5 - Creating Monitoring Schedule\n",
    "\n",
    "We can now set up the Data Quality Monitoring Job using the [DefaultModelMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "\n",
    "data_monitor = DefaultModelMonitor(\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    volume_size_in_gb=20,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af1681",
   "metadata": {},
   "source": [
    "Let's now create the monitoring schedule. Notice how we specify the `record_preprocessor_script` using the S3 location where we uploaded our script.\n",
    "\n",
    "We are going to set up the monitoring schedule to run every hour. Keep in mind that SageMaker has a buffer period of 20 minutes to schedule an execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7320924",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3fe69",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "import time\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "data_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=\"penguins-data-monitoring-schedule\",\n",
    "    endpoint_input=ENDPOINT,\n",
    "    record_preprocessor_script=data_quality_preprocessor,\n",
    "    statistics=f\"{DATA_QUALITY_LOCATION}/statistics.json\",\n",
    "    constraints=f\"{DATA_QUALITY_LOCATION}/constraints.json\",\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    output_s3_uri=DATA_QUALITY_LOCATION,\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\n",
    "# Let's give SageMaker some time to process the\n",
    "# monitoring job before we start it.\n",
    "time.sleep(10)\n",
    "data_monitor.start_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e38659",
   "metadata": {},
   "source": [
    "### Step 6 - Checking Violations\n",
    "\n",
    "After the monitoring schedule runs for the first time, we can check the results of the last execution. If the job completed successfully, we can check if there are any violations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_execution(monitoring_schedule):\n",
    "    \"\"\"Check the execution of the Monitoring Job.\n",
    "\n",
    "    This function checks the execution of the Monitoring\n",
    "    Job and prints out the list of violations if the job\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        executions = monitoring_schedule.list_executions()\n",
    "\n",
    "        if executions:\n",
    "            execution = executions[-1].describe()\n",
    "            print(f\"Processing Job Status: {execution['ProcessingJobStatus']}\")\n",
    "\n",
    "            if execution[\"ProcessingJobStatus\"] == \"Completed\":\n",
    "                print(f\"Exit Message: \\\"{execution['ExitMessage']}\\\"\")\n",
    "                print(\n",
    "                    f\"Last Modified Time: {execution['LastModifiedTime']}\",\n",
    "                    end=\"\\n\\n\",\n",
    "                )\n",
    "                print(\"Execution:\")\n",
    "                print(json.dumps(execution, default=str, indent=2), end=\"\\n\\n\")\n",
    "\n",
    "                latest_monitoring_violations = (\n",
    "                    monitoring_schedule.latest_monitoring_constraint_violations()\n",
    "                )\n",
    "                response = json.loads(\n",
    "                    S3Downloader.read_file(latest_monitoring_violations.file_s3_uri),\n",
    "                )\n",
    "                print(\"Violations:\")\n",
    "                print(json.dumps(response, indent=2))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "check_execution(data_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9faf0",
   "metadata": {},
   "source": [
    "### Step 7 - Deleting Monitoring Schedule\n",
    "\n",
    "Once we are done with it, we can delete the Data Monitoring schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_monitor.delete_monitoring_schedule()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec9a8b",
   "metadata": {},
   "source": [
    "## Session 19 - Model Monitoring\n",
    "\n",
    "This session creates a Monitoring Job to monitor the quality of the model outputs. This schedule will run periodically and check the data that goes into the endpoint against the baseline we generated before.\n",
    "\n",
    "Check [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html) for an explanation of how to use SageMaker's Model Monitoring functionality. [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) is a much more extensive guide to monitoring in Amazon SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ff7f2",
   "metadata": {},
   "source": [
    "### Step 1 - Configuring Ground Truth Location\n",
    "\n",
    "Let's start by defining the location where SageMaker will store the ground-truth generated by labeling the data received by the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddca53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_LOCATION = f\"{S3_LOCATION}/monitoring/groundtruth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c05a19",
   "metadata": {},
   "source": [
    "### Step 2 - Deploying the Model\n",
    "\n",
    "Let's deploy the latest approved model to an endpoint.\n",
    "\n",
    "Here, we can reuse the function we created before to deploy the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab3618",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2089ba4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#| eval: false\n",
    "\n",
    "deploy_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd4962",
   "metadata": {},
   "source": [
    "### Step 3 - Generating Fake Traffic\n",
    "\n",
    "To test the monitoring functionality, we need to generate traffic to the endpoint. We can use the function we created before to generate fake traffic to the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4545041",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "generate_fake_traffic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ff1ce",
   "metadata": {},
   "source": [
    "We can check the location where the endpoint stores the captured data, download a file, and display its content. It may take a few minutes for the first few files to show up in S3.\n",
    "\n",
    "These files contain the data captured by the endpoint in a SageMaker-specific JSON-line format. Each inference request is captured in a single line in the `jsonl` file. The line contains both the input and output merged together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = S3Downloader.list(DATA_CAPTURE_DESTINATION)\n",
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[-1])\n",
    "    print(f\"File: {files[-1]}\")\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ec421",
   "metadata": {},
   "source": [
    "### Step 4 - Generating Fake Labels\n",
    "\n",
    "To test the performance of the model, we need to label the samples captured by the endpoint. We can simulate the labeling process by generating a random label for every sample. Check [Ingest Ground Truth Labels and Merge Them With Predictions](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html) for more information about this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a32d8c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "records = []\n",
    "for inference_id in range(len(data)):\n",
    "    random.seed(inference_id)\n",
    "\n",
    "    records.append(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"groundTruthData\": {\n",
    "                    # For testing purposes, we will generate a random\n",
    "                    # label for each request.\n",
    "                    \"data\": random.choice([\"Adelie\", \"Chinstrap\", \"Gentoo\"]),\n",
    "                    \"encoding\": \"CSV\",\n",
    "                },\n",
    "                \"eventMetadata\": {\n",
    "                    # This value should match the id of the request\n",
    "                    # captured by the endpoint.\n",
    "                    \"eventId\": str(inference_id),\n",
    "                },\n",
    "                \"eventVersion\": \"0\",\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    "\n",
    "groundtruth_payload = \"\\n\".join(records)\n",
    "upload_time = datetime.now(tz=timezone.utc)\n",
    "uri = f\"{GROUND_TRUTH_LOCATION}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "S3Uploader.upload_string_as_file_body(groundtruth_payload, uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4a9cf",
   "metadata": {},
   "source": [
    "### Step 5 - Creating Monitoring Schedule\n",
    "\n",
    "To set up a Model Quality Monitoring Job, we can use the [ModelQualityMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelQualityMonitor) class.\n",
    "\n",
    "Check [Amazon SageMaker Model Quality Monitor](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.html) for a complete tutorial on how to run a Model Monitoring Job in SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54762759",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "\n",
    "model_monitor = ModelQualityMonitor(\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    volume_size_in_gb=20,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c392f",
   "metadata": {},
   "source": [
    "Let's now create the monitoring schedule. The [EndpointInput](https://sagemaker.readthedocs.io/en/v2.24.2/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.EndpointInput) instance configures the attribute the monitoring job should use to determine the prediction from the model.\n",
    "\n",
    "We are going to set up the monitoring schedule to run every hour. Keep in mind that SageMaker has a buffer period of 20 minutes to schedule an execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d28eb3",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665c61a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "import time\n",
    "\n",
    "from sagemaker.model_monitor import CronExpressionGenerator, EndpointInput\n",
    "\n",
    "model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=\"penguins-model-monitoring-schedule\",\n",
    "    endpoint_input=EndpointInput(\n",
    "        endpoint_name=ENDPOINT,\n",
    "        # The first attribute is the prediction made\n",
    "        # by the model. For example, here is a\n",
    "        # potential output from the model:\n",
    "        # [Adelie,0.977324724\\n]\n",
    "        inference_attribute=\"0\",\n",
    "        destination=\"/opt/ml/processing/input_data\",\n",
    "    ),\n",
    "    problem_type=\"MulticlassClassification\",\n",
    "    ground_truth_input=GROUND_TRUTH_LOCATION,\n",
    "    constraints=f\"{MODEL_QUALITY_LOCATION}/constraints.json\",\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    output_s3_uri=MODEL_QUALITY_LOCATION,\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\n",
    "# Let's give SageMaker some time to process the\n",
    "# monitoring job before we start it.\n",
    "time.sleep(10)\n",
    "model_monitor.start_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1e110",
   "metadata": {},
   "source": [
    "### Step 6 - Checking Violations\n",
    "\n",
    "After the monitoring schedule runs for the first time, we can check the results of the last execution. If the job completed successfully, we can check if there are any violations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_execution(model_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d403f00",
   "metadata": {},
   "source": [
    "### Step 7 - Deleting Monitoring Schedule\n",
    "\n",
    "Once we are done with it, we can delete the Data Monitoring schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f250115",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_monitor.delete_monitoring_schedule()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae348ea3",
   "metadata": {},
   "source": [
    "## Session 20 - Shadow Deployments\n",
    "\n",
    "This session configures an endpoint running a production and a shadow variant. Check [Safely validate models in production](https://docs.aws.amazon.com/sagemaker/latest/dg/model-validation.html) for more information.\n",
    "\n",
    "<a href=\"images/shadow-deployment.png\" target=\"_blank\"> <img src=\"images/shadow-deployment.png\" alt=\"Shadow Deployment\" style=\"max-width: 740px;\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19314442",
   "metadata": {},
   "source": [
    "### Step 1 - Getting The Latest Models\n",
    "\n",
    "We want to deploy the two latest approved models from the Model Registry to the same endpoint. The latest version of the model will act as the Shadow variant, and the previous version will act as the Production variant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.list_model_packages(\n",
    "    ModelPackageGroupName=BASIC_MODEL_PACKAGE_GROUP,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    SortBy=\"CreationTime\",\n",
    "    MaxResults=2,\n",
    ")\n",
    "\n",
    "if response[\"ModelPackageSummaryList\"]:\n",
    "    production_package = response[\"ModelPackageSummaryList\"][1][\"ModelPackageArn\"]\n",
    "    shadow_package = response[\"ModelPackageSummaryList\"][0][\"ModelPackageArn\"]\n",
    "else:\n",
    "    production_package = None\n",
    "    shadow_package = None\n",
    "\n",
    "print(f\"Production package: {production_package}\")\n",
    "print(f\"Shadow package: {shadow_package}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b7995",
   "metadata": {},
   "source": [
    "### Step 2 - Creating the Models\n",
    "\n",
    "We want to deploy the two packages to a new endpoint. We'll use the boto3 API to deploy these models.\n",
    "\n",
    "Let's start by creating the SageMaker Models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8aea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# We'll use a different name for this endpoint.\n",
    "SHADOW_DEPLOYMENT_ENDPOINT = \"shadow-penguins-endpoint\"\n",
    "\n",
    "# The timestamp will help us create unique name for the\n",
    "# name of the models.\n",
    "timestamp = time.strftime(\"%m%d%H%M%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29826d",
   "metadata": {},
   "source": [
    "Let's now create the Production model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20b354",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "production_model_name = f\"{SHADOW_DEPLOYMENT_ENDPOINT}-production-{timestamp}\"\n",
    "\n",
    "sagemaker_client.create_model(\n",
    "    ModelName=production_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\"ModelPackageName\": production_package}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41dac0",
   "metadata": {},
   "source": [
    "And now we can create the second model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2024f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_model_name = f\"{SHADOW_DEPLOYMENT_ENDPOINT}-shadow-{timestamp}\"\n",
    "\n",
    "sagemaker_client.create_model(\n",
    "    ModelName=shadow_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\"ModelPackageName\": shadow_package}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1215beb",
   "metadata": {},
   "source": [
    "### Step 3 - Creating the Endpoint Configuration\n",
    "\n",
    "We can now create the Endpoint Configuration using the two models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d35d1",
   "metadata": {},
   "source": [
    "Let's define the location where SageMaker will output the information captured by the Shadow variant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85769b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHADOW_DATA_DESTINATION = f\"{S3_LOCATION}/endpoint/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fe3bf",
   "metadata": {},
   "source": [
    "We can create the Endpoint Configuration now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969df4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{SHADOW_DEPLOYMENT_ENDPOINT}-config-{timestamp}\"\n",
    "\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": production_model_name,\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"VariantName\": \"ProductionTraffic\",\n",
    "        },\n",
    "    ],\n",
    "    ShadowProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": shadow_model_name,\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"VariantName\": \"ShadowTraffic\",\n",
    "        },\n",
    "    ],\n",
    "    DataCaptureConfig={\n",
    "        \"EnableCapture\": True,\n",
    "        \"InitialSamplingPercentage\": 100,\n",
    "        \"DestinationS3Uri\": SHADOW_DATA_DESTINATION,\n",
    "        \"CaptureOptions\": [\n",
    "            {\"CaptureMode\": \"Input\"},\n",
    "            {\"CaptureMode\": \"Output\"},\n",
    "        ],\n",
    "        \"CaptureContentTypeHeader\": {\n",
    "            \"CsvContentTypes\": [\"text/csv\", \"application/octect-stream\"],\n",
    "            \"JsonContentTypes\": [\"application/json\", \"application/octect-stream\"],\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8baad3",
   "metadata": {},
   "source": [
    "### Step 4 - Creating the Endpoint\n",
    "\n",
    "Finally, we can create the Endpoint using the Endpoint Configuration we created before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb879c",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "sagemaker_client.create_endpoint(\n",
    "    EndpointName=SHADOW_DEPLOYMENT_ENDPOINT,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248702a3",
   "metadata": {},
   "source": [
    "### Step 5 - Generating Traffic\n",
    "\n",
    "Let's generate some traffic to the endpoint so we can test the Shadow variant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069afdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"\"\"\n",
    "0.6569590202313976,-1.0813829646495108,1.2097102831892812,0.9226343641317372,1.0,0.0,0.0\n",
    "-0.7751048801481084,0.8822689351285553,-1.2168066120762704,0.9226343641317372,0.0,1.0,0.0\n",
    "-0.837387834894918,0.3386660813829646,-0.26237731892812,-1.92351941317372,0.0,0.0,1.0\n",
    "\"\"\"\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=SHADOW_DEPLOYMENT_ENDPOINT,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5f044",
   "metadata": {},
   "source": [
    "### Step 6 - Checking Captured Data\n",
    "\n",
    "Let's check the location where the endpoint stores the captured data, download a file, and display its content. It may take a few minutes for the first few files to show up in S3.\n",
    "\n",
    "The endpoint will capture the data for both the Production and the Shadow variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffadf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = S3Downloader.list(\n",
    "    f\"{SHADOW_DATA_DESTINATION}{SHADOW_DEPLOYMENT_ENDPOINT}/ShadowTraffic/\",\n",
    ")\n",
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[-1])\n",
    "    print(f\"File: {files[-1]}\")\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8535163",
   "metadata": {},
   "source": [
    "### Step 7 - Deleting the Endpoint\n",
    "\n",
    "Let's now delete the endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sagemaker_client.delete_endpoint(EndpointName=SHADOW_DEPLOYMENT_ENDPOINT)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f99c1",
   "metadata": {},
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "We can run any of the pipelines we defined before by enabling the cell below and specifying the pipeline we want to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01c152",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1e634",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# | eval: false\n",
    "\n",
    "session3_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5d383-fcd7-454c-bbd6-ce4ce7b2104a",
   "metadata": {},
   "source": [
    "## Deleting the Endpoint\n",
    "\n",
    "After testing the endpoint, we need to ensure we delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32c3a4-312e-473c-a217-33606f77d1e9",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sagemaker_client.delete_endpoint(EndpointName=ENDPOINT)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd7313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "mls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:325223348818:studio-lifecycle-config/packages",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
